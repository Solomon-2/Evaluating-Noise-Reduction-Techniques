{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Patient Groups: List of RML and EDF links for each patient ---\n",
    "patient_groups = [\n",
    "    {\n",
    "        \"rml_url\": \"RML_LINK_1\",\n",
    "        \"edf_urls\": [\"EDF_LINK_1A\", \"EDF_LINK_1B\"]\n",
    "    },\n",
    "    {\n",
    "        \"rml_url\": \"RML_LINK_2\",\n",
    "        \"edf_urls\": [\"EDF_LINK_2A\", \"EDF_LINK_2B\", \"EDF_LINK_2C\"]\n",
    "    },\n",
    "    # Add more patient groups as needed\n",
    "]\n",
    "\n",
    "base_dir = \"/content\"  # Or your working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7e13a",
   "metadata": {},
   "source": [
    "# Apnea Audio Data Preparation Notebook\n",
    "\n",
    "This notebook prepares data for apnea event detection/classification. It will:\n",
    "- Download EDF and RML files for a patient\n",
    "- Extract apnea events from the RML file\n",
    "- Concatenate all EDFs' 'Mic' channels into one large WAV file\n",
    "- Extract frame-by-frame features and labels, and append to a master CSV\n",
    "\n",
    "## Instructions\n",
    "1. Edit the download links and data directory in the first cell for each patient.\n",
    "2. Run all cells in order.\n",
    "3. Repeat for each patient (the master CSV will accumulate all data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Extract apnea events from RML ---\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_apnea_events(xml_file_path, output_csv=None):\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    namespace = {'ns': 'http://www.respironics.com/PatientStudy.xsd'}\n",
    "    apnea_events = []\n",
    "    for event in root.findall('.//ns:Event', namespace):\n",
    "        event_family = event.get('Family')\n",
    "        event_type = event.get('Type')\n",
    "        if (event_family == 'Respiratory' and event_type in ['ObstructiveApnea', 'CentralApnea', 'MixedApnea']):\n",
    "            start_time = float(event.get('Start'))\n",
    "            duration = float(event.get('Duration'))\n",
    "            end_time = start_time + duration\n",
    "            apnea_events.append((event_type, start_time, end_time))\n",
    "    apnea_events.sort(key=lambda x: x[1])\n",
    "    if output_csv:\n",
    "        with open(output_csv, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['event_type', 'start_sec', 'end_sec'])\n",
    "            for event_type, start, end in apnea_events:\n",
    "                writer.writerow([event_type, start, end])\n",
    "        print(f\"Extracted {len(apnea_events)} apnea events to {output_csv}\")\n",
    "    return apnea_events\n",
    "\n",
    "apnea_csv = os.path.join(data_dir, f\"{patient_id}_apnea_events.csv\")\n",
    "extract_apnea_events(rml_path, apnea_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0205a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "edf_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.lower().endswith('.edf')])\n",
    "output_wav = os.path.join(data_dir, f\"{patient_id}_fullmic.wav\")\n",
    "\n",
    "# Find the first EDF with a 'Mic' channel to get the sample rate\n",
    "sfreq = None\n",
    "for edf_path in edf_files:\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "    if \"Mic\" in raw.ch_names:\n",
    "        sfreq = int(raw.info[\"sfreq\"])\n",
    "        break\n",
    "\n",
    "if sfreq is None:\n",
    "    raise RuntimeError(\"No EDF file with a 'Mic' channel found.\")\n",
    "\n",
    "with sf.SoundFile(output_wav, 'w', samplerate=sfreq, channels=1, subtype='PCM_16') as out_f:\n",
    "    for edf_path in edf_files:\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "        if \"Mic\" not in raw.ch_names:\n",
    "            print(f\"❌ 'Mic' channel not found in {edf_path}!\")\n",
    "            continue\n",
    "        mic_idx = raw.ch_names.index(\"Mic\")\n",
    "        n_samples = raw.n_times\n",
    "        chunk_size = sfreq * 600  # 1 minute chunks\n",
    "        for start in range(0, n_samples, chunk_size):\n",
    "            stop = min(start + chunk_size, n_samples)\n",
    "            mic_chunk = raw.get_data(picks=[mic_idx], start=start, stop=stop)[0]\n",
    "            out_f.write(mic_chunk)\n",
    "        print(f\"Wrote {n_samples} samples from {edf_path}\")\n",
    "\n",
    "print(f\"Saved concatenated mic channel to {output_wav}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faedb9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import scipy.stats\n",
    "from scipy.signal import spectrogram\n",
    "import librosa\n",
    "\n",
    "def load_apnea_events(csv_path):\n",
    "    events = []\n",
    "    with open(csv_path, newline='') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            events.append((float(row['start_sec']), float(row['end_sec'])))\n",
    "    return events\n",
    "\n",
    "def is_apnea(frame_start, frame_end, events):\n",
    "    for start, end in events:\n",
    "        if frame_end > start and frame_start < end:\n",
    "            return 1  # apnea\n",
    "    return 0  # non-apnea\n",
    "\n",
    "def extract_features(frame, sr):\n",
    "    # Basic features\n",
    "    energy = np.mean(np.abs(frame))\n",
    "    zcr = ((frame[:-1] * frame[1:]) < 0).sum() / len(frame)\n",
    "    spectrum = np.abs(np.fft.rfft(frame))\n",
    "    freqs = np.fft.rfftfreq(len(frame), 1/sr)\n",
    "    centroid = np.sum(freqs * spectrum) / (np.sum(spectrum) + 1e-10)\n",
    "\n",
    "    # RMS energy\n",
    "    rms = np.sqrt(np.mean(frame ** 2))\n",
    "\n",
    "    # Spectral bandwidth\n",
    "    if np.sum(spectrum) > 0:\n",
    "        bandwidth = np.sqrt(np.sum(((freqs - centroid) ** 2) * spectrum) / np.sum(spectrum))\n",
    "    else:\n",
    "        bandwidth = 0.0\n",
    "\n",
    "    # Spectral rolloff (0.85)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=frame, sr=sr, roll_percent=0.85)[0, 0]\n",
    "\n",
    "    # Spectral flatness\n",
    "    flatness = librosa.feature.spectral_flatness(y=frame)[0, 0]\n",
    "\n",
    "    # MFCCs (first 13)\n",
    "    mfccs = librosa.feature.mfcc(y=frame, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "\n",
    "    # Skewness and kurtosis\n",
    "    skew = scipy.stats.skew(frame)\n",
    "    kurt = scipy.stats.kurtosis(frame)\n",
    "\n",
    "    # Spectrogram entropy (Shannon entropy of the power spectrum)\n",
    "    power_spec = spectrum ** 2\n",
    "    ps_norm = power_spec / (np.sum(power_spec) + 1e-10)\n",
    "    entropy = -np.sum(ps_norm * np.log2(ps_norm + 1e-10))\n",
    "\n",
    "    # Aggregate all features\n",
    "    features = [energy, zcr, centroid, rms, bandwidth, rolloff, flatness, skew, kurt, entropy] + list(mfccs_mean)\n",
    "    return features\n",
    "\n",
    "apnea_events = load_apnea_events(apnea_csv)\n",
    "master_csv = os.path.join(base_dir, \"master_apnea.csv\")\n",
    "header = ['filename', 'frame_start', 'frame_end', 'energy', 'zcr', 'centroid', 'rms', 'bandwidth', 'rolloff', 'flatness', 'skew', 'kurt', 'entropy'] + [f'mfcc_{i+1}' for i in range(13)] + ['label']\n",
    "\n",
    "write_header = not os.path.exists(master_csv) or os.stat(master_csv).st_size == 0\n",
    "\n",
    "with sf.SoundFile(output_wav, 'r') as f:\n",
    "    sr = f.samplerate\n",
    "    frame_sec = 1\n",
    "    frame_len = int(sr * frame_sec)\n",
    "    n_frames = int(np.floor(len(f) / frame_len))\n",
    "    with open(master_csv, 'a', newline='') as out_f:\n",
    "        writer = csv.writer(out_f)\n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "        for i in range(n_frames):\n",
    "            frame = f.read(frames=frame_len, dtype='float32')\n",
    "            if len(frame) < frame_len:\n",
    "                break\n",
    "            frame_start_sec = i * frame_sec\n",
    "            frame_end_sec = frame_start_sec + frame_sec\n",
    "            features = extract_features(frame, sr)\n",
    "            label = is_apnea(frame_start_sec, frame_end_sec, apnea_events)\n",
    "            writer.writerow([os.path.basename(output_wav), frame_start_sec, frame_end_sec] + list(features) + [label])\n",
    "print(f\"Appended {n_frames} frames to {master_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c862ab",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Change the download links and data_dir at the top for each new patient.\n",
    "- Run all cells to append new data to the master CSV.\n",
    "- The master CSV can now be used for classifier training in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loop through all patient groups and process each ---\n",
    "import os\n",
    "\n",
    "def download_file(url, out_path):\n",
    "    if not os.path.exists(out_path):\n",
    "        os.system(f\"wget -O '{out_path}' '{url}'\")\n",
    "    else:\n",
    "        print(f\"File already exists: {out_path}\")\n",
    "\n",
    "for idx, group in enumerate(patient_groups, 1):\n",
    "    patient_id = f\"patient_{idx}\"\n",
    "    data_dir = os.path.join(base_dir, patient_id)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    rml_path = os.path.join(data_dir, f\"{patient_id}.rml\")\n",
    "    download_file(group[\"rml_url\"], rml_path)\n",
    "    for i, edf_url in enumerate(group[\"edf_urls\"], 1):\n",
    "        edf_path = os.path.join(data_dir, f\"no_{i}.edf\")\n",
    "        download_file(edf_url, edf_path)\n",
    "    # After downloading, run all the data preparation steps for this patient\n",
    "    # You can wrap the rest of the notebook's logic in a function and call it here for each patient\n",
    "    # Example: process_patient(data_dir, patient_id)\n",
    "    # (Next cells will be refactored to support this loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3576bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to process a single patient directory ---\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import mne\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.signal import spectrogram\n",
    "import librosa\n",
    "\n",
    "def extract_apnea_events(xml_file_path, output_csv=None):\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    namespace = {'ns': 'http://www.respironics.com/PatientStudy.xsd'}\n",
    "    apnea_events = []\n",
    "    for event in root.findall('.//ns:Event', namespace):\n",
    "        event_family = event.get('Family')\n",
    "        event_type = event.get('Type')\n",
    "        if (event_family == 'Respiratory' and event_type in ['ObstructiveApnea', 'CentralApnea', 'MixedApnea']):\n",
    "            start_time = float(event.get('Start'))\n",
    "            duration = float(event.get('Duration'))\n",
    "            end_time = start_time + duration\n",
    "            apnea_events.append((event_type, start_time, end_time))\n",
    "    apnea_events.sort(key=lambda x: x[1])\n",
    "    if output_csv:\n",
    "        with open(output_csv, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['event_type', 'start_sec', 'end_sec'])\n",
    "            for event_type, start, end in apnea_events:\n",
    "                writer.writerow([event_type, start, end])\n",
    "        print(f\"Extracted {len(apnea_events)} apnea events to {output_csv}\")\n",
    "    return apnea_events\n",
    "\n",
    "def load_apnea_events(csv_path):\n",
    "    events = []\n",
    "    with open(csv_path, newline='') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            events.append((float(row['start_sec']), float(row['end_sec'])))\n",
    "    return events\n",
    "\n",
    "def is_apnea(frame_start, frame_end, events):\n",
    "    for start, end in events:\n",
    "        if frame_end > start and frame_start < end:\n",
    "            return 1  # apnea\n",
    "    return 0  # non-apnea\n",
    "\n",
    "def extract_features(frame, sr):\n",
    "    # Basic features\n",
    "    energy = np.mean(np.abs(frame))\n",
    "    zcr = ((frame[:-1] * frame[1:]) < 0).sum() / len(frame)\n",
    "    spectrum = np.abs(np.fft.rfft(frame))\n",
    "    freqs = np.fft.rfftfreq(len(frame), 1/sr)\n",
    "    centroid = np.sum(freqs * spectrum) / (np.sum(spectrum) + 1e-10)\n",
    "\n",
    "    # RMS energy\n",
    "    rms = np.sqrt(np.mean(frame ** 2))\n",
    "\n",
    "    # Spectral bandwidth\n",
    "    if np.sum(spectrum) > 0:\n",
    "        bandwidth = np.sqrt(np.sum(((freqs - centroid) ** 2) * spectrum) / np.sum(spectrum))\n",
    "    else:\n",
    "        bandwidth = 0.0\n",
    "\n",
    "    # Spectral rolloff (0.85)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=frame, sr=sr, roll_percent=0.85)[0, 0]\n",
    "\n",
    "    # Spectral flatness\n",
    "    flatness = librosa.feature.spectral_flatness(y=frame)[0, 0]\n",
    "\n",
    "    # MFCCs (first 13)\n",
    "    mfccs = librosa.feature.mfcc(y=frame, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "\n",
    "    # Skewness and kurtosis\n",
    "    skew = scipy.stats.skew(frame)\n",
    "    kurt = scipy.stats.kurtosis(frame)\n",
    "\n",
    "    # Spectrogram entropy (Shannon entropy of the power spectrum)\n",
    "    power_spec = spectrum ** 2\n",
    "    ps_norm = power_spec / (np.sum(power_spec) + 1e-10)\n",
    "    entropy = -np.sum(ps_norm * np.log2(ps_norm + 1e-10))\n",
    "\n",
    "    # Aggregate all features\n",
    "    features = [energy, zcr, centroid, rms, bandwidth, rolloff, flatness, skew, kurt, entropy] + list(mfccs_mean)\n",
    "    return features\n",
    "\n",
    "def process_patient(data_dir, patient_id):\n",
    "    print(f\"Processing {patient_id}\")\n",
    "    # 1. Extract apnea events from RML\n",
    "    rml_path = os.path.join(data_dir, f\"{patient_id}.rml\")\n",
    "    apnea_csv = os.path.join(data_dir, f\"{patient_id}_apnea_events.csv\")\n",
    "    extract_apnea_events(rml_path, apnea_csv)\n",
    "    # 2. Concatenate EDFs' Mic channels\n",
    "    edf_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.lower().endswith('.edf')])\n",
    "    output_wav = os.path.join(data_dir, f\"{patient_id}_fullmic.wav\")\n",
    "    sfreq = None\n",
    "    for edf_path in edf_files:\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "        if \"Mic\" in raw.ch_names:\n",
    "            sfreq = int(raw.info[\"sfreq\"])\n",
    "            break\n",
    "    if sfreq is None:\n",
    "        print(f\"No EDF file with a 'Mic' channel found for {patient_id}.\")\n",
    "        return\n",
    "    with sf.SoundFile(output_wav, 'w', samplerate=sfreq, channels=1, subtype='PCM_16') as out_f:\n",
    "        for edf_path in edf_files:\n",
    "            raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "            if \"Mic\" not in raw.ch_names:\n",
    "                print(f\"❌ 'Mic' channel not found in {edf_path}!\")\n",
    "                continue\n",
    "            mic_idx = raw.ch_names.index(\"Mic\")\n",
    "            n_samples = raw.n_times\n",
    "            chunk_size = sfreq * 600  # 1 minute chunks\n",
    "            for start in range(0, n_samples, chunk_size):\n",
    "                stop = min(start + chunk_size, n_samples)\n",
    "                mic_chunk = raw.get_data(picks=[mic_idx], start=start, stop=stop)[0]\n",
    "                out_f.write(mic_chunk)\n",
    "            print(f\"Wrote {n_samples} samples from {edf_path}\")\n",
    "    print(f\"Saved concatenated mic channel to {output_wav}\")\n",
    "    # 3. Extract features and labels, append to master CSV\n",
    "    apnea_events = load_apnea_events(apnea_csv)\n",
    "    master_csv = os.path.join(base_dir, \"master_apnea.csv\")\n",
    "    header = ['filename', 'frame_start', 'frame_end', 'energy', 'zcr', 'centroid', 'rms', 'bandwidth', 'rolloff', 'flatness', 'skew', 'kurt', 'entropy'] + [f'mfcc_{i+1}' for i in range(13)] + ['label']\n",
    "    write_header = not os.path.exists(master_csv) or os.stat(master_csv).st_size == 0\n",
    "    with sf.SoundFile(output_wav, 'r') as f:\n",
    "        sr = f.samplerate\n",
    "        frame_sec = 1\n",
    "        frame_len = int(sr * frame_sec)\n",
    "        n_frames = int(np.floor(len(f) / frame_len))\n",
    "        with open(master_csv, 'a', newline='') as out_f:\n",
    "            writer = csv.writer(out_f)\n",
    "            if write_header:\n",
    "                writer.writerow(header)\n",
    "            for i in range(n_frames):\n",
    "                frame = f.read(frames=frame_len, dtype='float32')\n",
    "                if len(frame) < frame_len:\n",
    "                    break\n",
    "                frame_start_sec = i * frame_sec\n",
    "                frame_end_sec = frame_start_sec + frame_sec\n",
    "                features = extract_features(frame, sr)\n",
    "                label = is_apnea(frame_start_sec, frame_end_sec, apnea_events)\n",
    "                writer.writerow([os.path.basename(output_wav), frame_start_sec, frame_end_sec] + list(features) + [label])\n",
    "    print(f\"Appended {n_frames} frames to master CSV for {patient_id}\")\n",
    "\n",
    "# --- Run all patients ---\n",
    "for idx, group in enumerate(patient_groups, 1):\n",
    "    patient_id = f\"patient_{idx}\"\n",
    "    data_dir = os.path.join(base_dir, patient_id)\n",
    "    print(f\"\\n=== Processing {patient_id} ===\")\n",
    "    rml_path = os.path.join(data_dir, f\"{patient_id}.rml\")\n",
    "    # Download files (already done above)\n",
    "    process_patient(data_dir, patient_id)\n",
    "    print(f\"Finished {patient_id}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
