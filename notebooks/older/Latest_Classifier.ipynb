{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d277ccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Core ML Libraries ---\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, ParameterGrid, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Models to Compare ---\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb # LightGBM for Gradient Boosting\n",
    "\n",
    "# --- Metrics ---\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9925cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_9648\\531094604.py:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  DATASET_PATH = \"..\\poc_dataset_2.csv\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded '..\\poc_dataset_2.csv' with 342722 frames from 20 patients.\n",
      "\n",
      "Label Distribution:\n",
      "label\n",
      "0    0.743935\n",
      "1    0.256065\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Final Dataset\n",
    "\n",
    "# --- IMPORTANT: Update this path if your dataset has a different name ---\n",
    "DATASET_PATH = \"..\\poc_dataset_2.csv\"\n",
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    print(f\"Successfully loaded '{DATASET_PATH}' with {len(df)} frames from {len(df['patient_id'].unique())} patients.\")\n",
    "else:\n",
    "    print(f\"FATAL ERROR: Dataset '{DATASET_PATH}' not found. Please create it first.\")\n",
    "    df = pd.DataFrame() # Create empty dataframe to prevent further errors\n",
    "\n",
    "if not df.empty:\n",
    "  # Prepare data for the models\n",
    "  X = df.drop(columns=['patient_id', 'label'])\n",
    "  y = df['label']\n",
    "  groups = df['patient_id'] # This is crucial for GroupKFold\n",
    "\n",
    "  # Display data info as a final check\n",
    "  print(\"\\nLabel Distribution:\")\n",
    "  print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3d4e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Will train and evaluate 3 models:\n",
      "- LogisticRegression\n",
      "- RandomForest\n",
      "- LightGBM\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Setup for Training and Evaluation\n",
    "\n",
    "# --- 1. Define the Cross-Validation Strategy ---\n",
    "# We use GroupKFold to ensure that data from the same patient is never in both\n",
    "# the training and validation fold within the grid search. This gives a realistic performance estimate.\n",
    "cv_strategy = GroupKFold(n_splits=5) # 5-fold cross-validation is a robust standard\n",
    "\n",
    "\n",
    "# --- 2. Define the Models and their Hyperparameter Grids for Tuning ---\n",
    "\n",
    "# We will store our models and their settings in a dictionary for easy iteration\n",
    "models_to_train = {}\n",
    "\n",
    "# Model A: Logistic Regression (Fast Baseline)\n",
    "# It's a simple linear model, so tuning is minimal.\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000, solver='liblinear'))\n",
    "])\n",
    "lr_param_grid = {\n",
    "    'classifier__C': [0.1, 1.0, 10.0] # Regularization strength\n",
    "}\n",
    "models_to_train['LogisticRegression'] = (lr_pipeline, lr_param_grid)\n",
    "\n",
    "\n",
    "# Model B: Random Forest (Robust Workhorse)\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1))\n",
    "])\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [150, 250],\n",
    "    'classifier__max_depth': [15, 25, None],\n",
    "    'classifier__min_samples_leaf': [1, 3]\n",
    "}\n",
    "models_to_train['RandomForest'] = (rf_pipeline, rf_param_grid)\n",
    "\n",
    "\n",
    "# Model C: LightGBM (Fast & Powerful Gradient Boosting)\n",
    "lgbm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', lgb.LGBMClassifier(random_state=42, objective='binary'))\n",
    "])\n",
    "# For imbalanced data, LightGBM often works well by adjusting 'scale_pos_weight'\n",
    "pos_weight = y.value_counts()[0] / y.value_counts()[1]\n",
    "lgbm_param_grid = {\n",
    "    'classifier__n_estimators': [150, 250],\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "    'classifier__num_leaves': [31, 50],\n",
    "    'classifier__scale_pos_weight': [pos_weight] # Key parameter for imbalance\n",
    "}\n",
    "models_to_train['LightGBM'] = (lgbm_pipeline, lgbm_param_grid)\n",
    "\n",
    "print(f\"Setup complete. Will train and evaluate {len(models_to_train)} models:\")\n",
    "for name in models_to_train:\n",
    "    print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437d8044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Model: LogisticRegression ---\n",
      "Performing 15 fits for LogisticRegression...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1675a8ec4ad94923ad9def605713a8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training LogisticRegression. Best F1-Score (weighted): 0.5108\n",
      "\n",
      "--- Training Model: RandomForest ---\n",
      "Performing 60 fits for RandomForest...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc46e68e7b594def89030299abe95867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training RandomForest. Best F1-Score (weighted): 0.6438\n",
      "\n",
      "--- Training Model: LightGBM ---\n",
      "Performing 40 fits for LightGBM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43432097a0af4576899cdb3f96c623b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 87759, number of negative: 254963\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4080\n",
      "[LightGBM] [Info] Number of data points in the train set: 342722, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.256065 -> initscore=-1.066524\n",
      "[LightGBM] [Info] Start training from score -1.066524\n",
      "Finished training LightGBM. Best F1-Score (weighted): 0.4923\n",
      "\n",
      "--- All models have been trained. ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: The Training Loop\n",
    "\n",
    "# This dictionary will hold the results for each model\n",
    "model_results = {}\n",
    "\n",
    "# Loop through each model defined in Cell 3\n",
    "for model_name, (pipeline, param_grid) in models_to_train.items():\n",
    "    \n",
    "    print(f\"\\n--- Training Model: {model_name} ---\")\n",
    "    \n",
    "    # Set up GridSearchCV for the current model\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=cv_strategy,\n",
    "        scoring='f1_weighted', # Use weighted F1-score for overall performance\n",
    "        n_jobs=-1,\n",
    "        verbose=0 # Using TQDM for progress bar\n",
    "    )\n",
    "    \n",
    "    # Calculate total fits for the progress bar\n",
    "    num_fits = len(ParameterGrid(param_grid)) * cv_strategy.get_n_splits(X, y, groups)\n",
    "    print(f\"Performing {num_fits} fits for {model_name}...\")\n",
    "\n",
    "    # Run the grid search with a progress bar\n",
    "    with tqdm(total=num_fits) as pbar:\n",
    "        with joblib.parallel_backend('threading'):\n",
    "            grid_search.fit(X, y, groups=groups)\n",
    "\n",
    "    # Store the best score and best parameters found\n",
    "    model_results[model_name] = {\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_estimator': grid_search.best_estimator_ # Save the trained best model\n",
    "    }\n",
    "    \n",
    "    print(f\"Finished training {model_name}. Best F1-Score (weighted): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\n--- All models have been trained. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271a6d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Performance Summary ---\n",
      "-----------------------------------\n",
      "                Model  Best F1-Score (Weighted)\n",
      "1        RandomForest                  0.643846\n",
      "0  LogisticRegression                  0.510807\n",
      "2            LightGBM                  0.492325\n",
      "\n",
      "--- Champion Model: RandomForest with F1-Score: 0.6438 ---\n",
      "\n",
      "Best Parameters Found:\n",
      "{'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 150}\n",
      "\n",
      "--- Final Validation of Champion Model on a Hold-Out Test Set ---\n",
      "Retraining champion model on the training split...\n",
      "Retraining complete.\n",
      "\n",
      "--- Test Set Performance ---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "missing a required argument: 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m y_pred = best_model.predict(X_test)\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Test Set Performance ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNo Apnea\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mApnea\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Display the confusion matrix for the champion model\u001b[39;00m\n\u001b[32m     51\u001b[39m ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test, display_labels=[\u001b[33m'\u001b[39m\u001b[33mNo Apnea\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mApnea\u001b[39m\u001b[33m'\u001b[39m], cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\solom\\Documents\\Evaluating-Noise-Reduction-Techniques\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:194\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m params.apply_defaults()\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\inspect.py:3295\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3290\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3291\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3292\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3293\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3294\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\inspect.py:3208\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3206\u001b[39m                 msg = \u001b[33m'\u001b[39m\u001b[33mmissing a required\u001b[39m\u001b[38;5;132;01m{argtype}\u001b[39;00m\u001b[33m argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m   3207\u001b[39m                 msg = msg.format(arg=param.name, argtype=argtype)\n\u001b[32m-> \u001b[39m\u001b[32m3208\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3210\u001b[39m     \u001b[38;5;66;03m# We have a positional argument to process\u001b[39;00m\n\u001b[32m   3211\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: missing a required argument: 'y_pred'"
     ]
    }
   ],
   "source": [
    "# Cell 5: Results Summary and Comparison\n",
    "\n",
    "print(\"--- Model Performance Summary ---\")\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "# Convert results to a DataFrame for easy viewing and sorting\n",
    "results_df = pd.DataFrame(\n",
    "    [(model_name, info['best_score']) for model_name, info in model_results.items()],\n",
    "    columns=['Model', 'Best F1-Score (Weighted)']\n",
    ").sort_values(by='Best F1-Score (Weighted)', ascending=False)\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "# Identify the champion model\n",
    "champion_model_name = results_df.iloc[0]['Model']\n",
    "champion_model_info = model_results[champion_model_name]\n",
    "best_f1_score = champion_model_info['best_score']\n",
    "best_model = champion_model_info['best_estimator']\n",
    "\n",
    "print(f\"\\n--- Champion Model: {champion_model_name} with F1-Score: {best_f1_score:.4f} ---\")\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "print(champion_model_info['best_params'])\n",
    "\n",
    "\n",
    "# --- Final Evaluation of the Champion Model on a Hold-Out Test Set ---\n",
    "# For a final, unbiased evaluation, we should test the champion on data it has NEVER seen.\n",
    "# We'll split the data one more time, retrain the best model on the full training part,\n",
    "# and evaluate on the held-out test part.\n",
    "\n",
    "print(\"\\n--- Final Validation of Champion Model on a Hold-Out Test Set ---\")\n",
    "# Stratify by patient to try and get a mix of patients in train/test\n",
    "# This is a simple split; for rigorous results, one might do leave-one-patient-out CV\n",
    "train_indices, test_indices = next(GroupKFold(n_splits=5).split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "\n",
    "# Retrain the champion model on the larger training set\n",
    "print(\"Retraining champion model on the training split...\")\n",
    "best_model.fit(X_train, y_train)\n",
    "print(\"Retraining complete.\")\n",
    "\n",
    "# Evaluate on the unseen test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Test Set Performance ---\")\n",
    "print(classification_report(y_test, target_names=['No Apnea', 'Apnea']))\n",
    "\n",
    "# Display the confusion matrix for the champion model\n",
    "ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test, display_labels=['No Apnea', 'Apnea'], cmap='Blues')\n",
    "plt.title(f'Confusion Matrix for Champion Model ({champion_model_name})')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
