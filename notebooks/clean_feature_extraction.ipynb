{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Feature Extraction for Sleep Apnea Detection\n",
    "## Modified from augumented_data_prep.ipynb to focus on clean feature extraction only\n",
    "### Noise injection and denoising code preserved but commented out for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 2: Imports and Setup\n",
    "# print(\"--- Importing libraries... ---\")\n",
    "\n",
    "# # Standard libraries\n",
    "# import os\n",
    "# import re\n",
    "# import shutil\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm.notebook import tqdm\n",
    "# import soundfile as sf\n",
    "# import warnings\n",
    "# import time\n",
    "# # import subprocess # For running external scripts - COMMENTED OUT for clean extraction\n",
    "\n",
    "# # For audio and signal processing\n",
    "# import librosa\n",
    "# import mne\n",
    "# from xml.etree import ElementTree as ET\n",
    "\n",
    "# # --- Import your custom XML parser ---\n",
    "# import sys\n",
    "# sys.path.append('../src') # Add the directory to Python's path\n",
    "# from working_with_xml import extract_apnea_events # Your specific function\n",
    "\n",
    "# # Suppress minor warnings from libraries to keep output clean\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# print(\"Libraries imported successfully.\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load all datasets\n",
    "batch5 = pd.read_csv('../data/datasets/colab_dataset_batch5.csv')\n",
    "batch6 = pd.read_csv('../data/datasets/colab_dataset_batch6.csv')\n",
    "local = pd.read_csv('../data/datasets/final_local_dataset.csv')\n",
    "\n",
    "# Combine into single dataset\n",
    "combined_dataset = pd.concat([batch5, batch6, local], ignore_index=True)\n",
    "\n",
    "# Save combined dataset\n",
    "combined_dataset.to_csv('../data/datasets/combined_complete_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuring clean feature extraction pipeline (30-second frames)... ---\n",
      "Configuration set for 30-second frame extraction with 10.0% apnea threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_14028\\140750516.py:6: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  RAW_PATIENT_DATA_BASE_DIR = \"F:\\Solo All In One Docs\\Evaluating-Noise-Reduction-Techniques\\data\\sleep_data\"  # Update this to your local path\n",
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_14028\\140750516.py:7: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  CSV_OUTPUT_PATH = \"F:\\Solo All In One Docs\\Evaluating-Noise-Reduction-Techniques\\data\\sleep_data\"  # Where to save the final dataset\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Configuration - Clean Feature Extraction Focus\n",
    "print(\"--- Configuring clean feature extraction pipeline (30-second frames)... ---\")\n",
    "\n",
    "# --- FILE & PATH SETTINGS ---\n",
    "# Path to your local patient data\n",
    "RAW_PATIENT_DATA_BASE_DIR = \"F:\\Solo All In One Docs\\Evaluating-Noise-Reduction-Techniques\\data\\sleep_data\"  # Update this to your local path\n",
    "CSV_OUTPUT_PATH = \"F:\\Solo All In One Docs\\Evaluating-Noise-Reduction-Techniques\\data\\sleep_data\"  # Where to save the final dataset\n",
    "\n",
    "# COMMENTED OUT - Noise/Denoising paths for future use\n",
    "# NOISE_AUDIO_DIR = \"noise_audio\" \n",
    "# DENOISER_SCRIPTS_DIR = os.path.abspath(\"../src\")\n",
    "\n",
    "# List the specific patient folders you want to process.\n",
    "PATIENT_FOLDERS_TO_PROCESS = []  # Empty = process all found patient folders\n",
    "# Example: ['patient_01', 'patient_02', 'patient_03']\n",
    "\n",
    "# --- DEBUG MODE SETTINGS ---\n",
    "DEBUG_MODE = True  # Set to False for full processing\n",
    "DEBUG_PATIENT_COUNT = 6 # In debug mode, process only this many patients\n",
    "\n",
    "# --- DATA PROCESSING SETTINGS (UPDATED FOR TEMPORAL ANALYSIS) ---\n",
    "AUDIO_CHANNEL_NAME = 'Mic'  # The microphone channel name from your EDF files\n",
    "FRAME_DURATION_SEC = 30.0  # 30-second frames for temporal pattern analysis\n",
    "CHUNK_DURATION_MIN = 10  # Process audio in chunks to manage RAM\n",
    "APNEA_THRESHOLD = 0.1  # 10% apnea content threshold for binary labeling\n",
    "\n",
    "# --- TEMPORAL FEATURE SETTINGS ---\n",
    "OVERLAP_RATIO = 0.5  # 50% overlap between consecutive frames\n",
    "BREATHING_RATE_WINDOW = 10  # Window size for breathing rate analysis (seconds)\n",
    "\n",
    "# COMMENTED OUT - Noise injection settings for future use\n",
    "# NOISE_CATEGORIES = ['vacuum_cleaner', 'cat', 'door_wood_creaks']\n",
    "# NOISE_LEVEL_RMS_RATIO = 0.3333\n",
    "# SAVE_SNIPPETS = True\n",
    "# SNIPPET_DURATION_SEC = 5\n",
    "\n",
    "# COMMENTED OUT - Denoiser script mapping for future use\n",
    "# DENOISER_SCRIPT_MAP = {\n",
    "#     \"spectral\": \"spec_subtraction_same_file.py\",\n",
    "#     \"wiener\": \"wiener_filtering.py\", \n",
    "#     \"logmmse\": \"log_mmse.py\",\n",
    "# }\n",
    "\n",
    "print(f\"Configuration set for 30-second frame extraction with {APNEA_THRESHOLD*100}% apnea threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Defining helper functions and main processing function for 30-second temporal feature extraction... ---\n",
      "Enhanced helper functions and process_single_patient function defined for 30-second temporal feature extraction.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Helper Functions + Main Processing Function\n",
    "print(\"--- Defining helper functions and main processing function for 30-second temporal feature extraction... ---\")\n",
    "\n",
    "# --- Wrapper for your external RML parser ---\n",
    "def parse_respironics_rml(rml_path):\n",
    "    \"\"\"Wraps your extract_apnea_events function to return (start_time, end_time) tuples.\"\"\"\n",
    "    apnea_event_data = extract_apnea_events(rml_path, output_csv=None)\n",
    "    events_only_times = [(float(start), float(end)) for event_type, start, end in apnea_event_data]\n",
    "    return events_only_times\n",
    "\n",
    "def calculate_apnea_proportion(frame_start_sec, frame_duration_sec, apnea_events):\n",
    "    \"\"\"Calculate proportion of frame that contains apnea events.\"\"\"\n",
    "    frame_end_sec = frame_start_sec + frame_duration_sec\n",
    "    apnea_seconds = 0\n",
    "    \n",
    "    for start, end in apnea_events:\n",
    "        # Calculate overlap between frame and apnea event\n",
    "        overlap_start = max(frame_start_sec, start)\n",
    "        overlap_end = min(frame_end_sec, end)\n",
    "        if overlap_start < overlap_end:\n",
    "            apnea_seconds += (overlap_end - overlap_start)\n",
    "    \n",
    "    return apnea_seconds / frame_duration_sec\n",
    "\n",
    "def label_temporal_frame(frame_start_sec, frame_duration_sec, apnea_events, threshold=0.1):\n",
    "    \"\"\"Label frame based on apnea proportion with threshold.\"\"\"\n",
    "    proportion = calculate_apnea_proportion(frame_start_sec, frame_duration_sec, apnea_events)\n",
    "    return 1 if proportion > threshold else 0, proportion\n",
    "\n",
    "def extract_basic_features(frame, sr):\n",
    "    \"\"\"Extract basic acoustic features from a frame.\"\"\"\n",
    "    # Ensure frame has data\n",
    "    if len(frame) == 0:\n",
    "        return {}\n",
    "        \n",
    "    rms = librosa.feature.rms(y=frame).mean()\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=frame).mean()\n",
    "    \n",
    "    try:\n",
    "        centroid = librosa.feature.spectral_centroid(y=frame, sr=sr).mean()\n",
    "        bandwidth = librosa.feature.spectral_bandwidth(y=frame, sr=sr).mean()\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=frame, sr=sr).mean()\n",
    "    except:\n",
    "        centroid = bandwidth = rolloff = 0\n",
    "    \n",
    "    # Extract MFCCs\n",
    "    try:\n",
    "        mfccs = librosa.feature.mfcc(y=frame, sr=sr, n_mfcc=13)\n",
    "        mfccs_mean = mfccs.mean(axis=1)\n",
    "        mfccs_std = mfccs.std(axis=1)\n",
    "    except:\n",
    "        mfccs_mean = np.zeros(13)\n",
    "        mfccs_std = np.zeros(13)\n",
    "    \n",
    "    features = {\n",
    "        'rms': rms,\n",
    "        'zcr': zcr, \n",
    "        'centroid': centroid,\n",
    "        'bandwidth': bandwidth,\n",
    "        'rolloff': rolloff\n",
    "    }\n",
    "    \n",
    "    # Add MFCC means and standard deviations\n",
    "    for i, (mean_val, std_val) in enumerate(zip(mfccs_mean, mfccs_std), 1):\n",
    "        features[f'mfcc_{i}_mean'] = mean_val\n",
    "        features[f'mfcc_{i}_std'] = std_val\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_temporal_features(frame, sr, window_sec=5):\n",
    "    \"\"\"Extract temporal breathing pattern features from 30-second frame.\"\"\"\n",
    "    frame_duration = len(frame) / sr\n",
    "    \n",
    "    # Split frame into sub-windows for temporal analysis\n",
    "    window_samples = int(window_sec * sr)\n",
    "    n_windows = int(len(frame) // window_samples)\n",
    "    \n",
    "    if n_windows < 2:\n",
    "        return {}\n",
    "    \n",
    "    # Extract features from each sub-window\n",
    "    sub_window_features = []\n",
    "    for i in range(n_windows):\n",
    "        start_idx = i * window_samples\n",
    "        end_idx = min((i + 1) * window_samples, len(frame))\n",
    "        sub_frame = frame[start_idx:end_idx]\n",
    "        \n",
    "        if len(sub_frame) > sr * 0.5:  # At least 0.5 seconds\n",
    "            sub_rms = librosa.feature.rms(y=sub_frame).mean()\n",
    "            sub_zcr = librosa.feature.zero_crossing_rate(y=sub_frame).mean()\n",
    "            sub_window_features.append({'rms': sub_rms, 'zcr': sub_zcr})\n",
    "    \n",
    "    if len(sub_window_features) < 2:\n",
    "        return {}\n",
    "    \n",
    "    # Calculate temporal variability features\n",
    "    rms_values = [f['rms'] for f in sub_window_features]\n",
    "    zcr_values = [f['zcr'] for f in sub_window_features]\n",
    "    \n",
    "    temporal_features = {\n",
    "        'rms_temporal_mean': np.mean(rms_values),\n",
    "        'rms_temporal_std': np.std(rms_values),\n",
    "        'rms_temporal_range': np.max(rms_values) - np.min(rms_values),\n",
    "        'zcr_temporal_mean': np.mean(zcr_values),\n",
    "        'zcr_temporal_std': np.std(zcr_values),\n",
    "        'zcr_temporal_range': np.max(zcr_values) - np.min(zcr_values),\n",
    "    }\n",
    "    \n",
    "    # Breathing regularity (coefficient of variation)\n",
    "    if temporal_features['rms_temporal_mean'] > 0:\n",
    "        temporal_features['rms_regularity'] = temporal_features['rms_temporal_std'] / temporal_features['rms_temporal_mean']\n",
    "    else:\n",
    "        temporal_features['rms_regularity'] = 0\n",
    "        \n",
    "    if temporal_features['zcr_temporal_mean'] > 0:\n",
    "        temporal_features['zcr_regularity'] = temporal_features['zcr_temporal_std'] / temporal_features['zcr_temporal_mean']\n",
    "    else:\n",
    "        temporal_features['zcr_regularity'] = 0\n",
    "    \n",
    "    return temporal_features\n",
    "\n",
    "def extract_silence_features(frame, sr, silence_threshold=0.01):\n",
    "    \"\"\"Extract silence/pause detection features.\"\"\"\n",
    "    # Identify silent segments\n",
    "    frame_abs = np.abs(frame)\n",
    "    silent_mask = frame_abs < silence_threshold\n",
    "    \n",
    "    # Calculate silence statistics\n",
    "    total_samples = len(frame)\n",
    "    silent_samples = np.sum(silent_mask)\n",
    "    silence_ratio = silent_samples / total_samples\n",
    "    \n",
    "    # Find continuous silent segments\n",
    "    silent_segments = []\n",
    "    in_silence = False\n",
    "    silence_start = 0\n",
    "    \n",
    "    for i, is_silent in enumerate(silent_mask):\n",
    "        if is_silent and not in_silence:\n",
    "            silence_start = i\n",
    "            in_silence = True\n",
    "        elif not is_silent and in_silence:\n",
    "            silence_duration = (i - silence_start) / sr\n",
    "            silent_segments.append(silence_duration)\n",
    "            in_silence = False\n",
    "    \n",
    "    # Handle case where frame ends in silence\n",
    "    if in_silence:\n",
    "        silence_duration = (len(silent_mask) - silence_start) / sr\n",
    "        silent_segments.append(silence_duration)\n",
    "    \n",
    "    silence_features = {\n",
    "        'silence_ratio': silence_ratio,\n",
    "        'silence_count': len(silent_segments),\n",
    "        'silence_mean_duration': np.mean(silent_segments) if silent_segments else 0,\n",
    "        'silence_max_duration': np.max(silent_segments) if silent_segments else 0,\n",
    "        'silence_total_duration': np.sum(silent_segments) if silent_segments else 0,\n",
    "    }\n",
    "    \n",
    "    return silence_features\n",
    "\n",
    "def extract_comprehensive_features(frame, sr):\n",
    "    \"\"\"Extract all features for 30-second temporal analysis.\"\"\"\n",
    "    # Basic acoustic features\n",
    "    basic_features = extract_basic_features(frame, sr)\n",
    "    \n",
    "    # Temporal breathing pattern features\n",
    "    temporal_features = extract_temporal_features(frame, sr)\n",
    "    \n",
    "    # Silence/pause features\n",
    "    silence_features = extract_silence_features(frame, sr)\n",
    "    \n",
    "    # Combine all features\n",
    "    all_features = {}\n",
    "    all_features.update(basic_features)\n",
    "    all_features.update(temporal_features)\n",
    "    all_features.update(silence_features)\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "def process_single_patient(patient_folder_name, patient_base_dir, patient_idx=0, total_patients=1):\n",
    "    \"\"\"Process a single patient with 30-second temporal frames.\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PATIENT {patient_idx+1}/{total_patients}: {patient_folder_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    patient_local_dir = os.path.join(patient_base_dir, patient_folder_name)\n",
    "    patient_features = []\n",
    "    \n",
    "    # Find EDF and RML files\n",
    "    print(f\"🔍 Scanning files in {patient_local_dir}...\")\n",
    "    edf_files = sorted([f for f in os.listdir(patient_local_dir) if f.endswith('.edf')])\n",
    "    rml_files = sorted([f for f in os.listdir(patient_local_dir) if f.endswith('.rml')])\n",
    "    \n",
    "    print(f\"   Found {len(edf_files)} EDF files: {edf_files}\")\n",
    "    print(f\"   Found {len(rml_files)} RML files: {rml_files}\")\n",
    "    \n",
    "    if not edf_files:\n",
    "        print(f\"❌ No EDF files found for {patient_folder_name}\")\n",
    "        return []\n",
    "        \n",
    "    if not rml_files:\n",
    "        print(f\"❌ No RML files found for {patient_folder_name}\")\n",
    "        return []\n",
    "    \n",
    "    # Process each EDF file\n",
    "    for edf_idx, edf_file in enumerate(edf_files):\n",
    "        print(f\"\\n📁 Processing EDF {edf_idx+1}/{len(edf_files)}: {edf_file}\")\n",
    "        edf_path = os.path.join(patient_local_dir, edf_file)\n",
    "        rml_path = os.path.join(patient_local_dir, rml_files[0])  # Assume first RML file\n",
    "        \n",
    "        try:\n",
    "            # Load apnea events\n",
    "            print(f\"   📋 Loading apnea events from {rml_files[0]}...\")\n",
    "            apnea_events = parse_respironics_rml(rml_path)\n",
    "            print(f\"   ✅ Found {len(apnea_events)} apnea events\")\n",
    "            \n",
    "            # Load EDF file\n",
    "            print(f\"   🎵 Loading EDF file...\")\n",
    "            raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "            fs = int(raw.info['sfreq'])\n",
    "            total_duration_sec = raw.n_times / fs\n",
    "            total_duration_min = total_duration_sec / 60\n",
    "            \n",
    "            print(f\"   📊 Sample rate: {fs} Hz\")\n",
    "            print(f\"   ⏱️  Total duration: {total_duration_min:.1f} minutes ({total_duration_sec:.0f} seconds)\")\n",
    "            print(f\"   🎤 Available channels: {raw.ch_names}\")\n",
    "            \n",
    "            # Check if microphone channel exists\n",
    "            if AUDIO_CHANNEL_NAME not in raw.ch_names:\n",
    "                print(f\"   ❌ Channel '{AUDIO_CHANNEL_NAME}' not found in {edf_file}\")\n",
    "                continue\n",
    "                \n",
    "            raw.pick_channels([AUDIO_CHANNEL_NAME])\n",
    "            print(f\"   ✅ Selected channel: {AUDIO_CHANNEL_NAME}\")\n",
    "            \n",
    "            # Calculate frame parameters\n",
    "            frame_size_samples = int(FRAME_DURATION_SEC * fs)\n",
    "            overlap_samples = int(frame_size_samples * OVERLAP_RATIO)\n",
    "            step_samples = frame_size_samples - overlap_samples\n",
    "            \n",
    "            # Estimate number of 30-second frames\n",
    "            total_frames = max(1, (raw.n_times - frame_size_samples) // step_samples + 1)\n",
    "            \n",
    "            print(f\"   📦 Processing in {FRAME_DURATION_SEC}-second frames with {OVERLAP_RATIO*100}% overlap\")\n",
    "            print(f\"   🎞️  Estimated frames: {total_frames}\")\n",
    "            \n",
    "            frame_count = 0\n",
    "            \n",
    "            # Process in overlapping 30-second frames\n",
    "            for frame_start in range(0, raw.n_times - frame_size_samples + 1, step_samples):\n",
    "                frame_end = min(frame_start + frame_size_samples, raw.n_times)\n",
    "                \n",
    "                if frame_end - frame_start < frame_size_samples * 0.8:  # Skip short frames (< 80% of target)\n",
    "                    continue\n",
    "                \n",
    "                frame_progress = (frame_count + 1) / total_frames * 100\n",
    "                print(f\"      🔄 Frame {frame_count+1}/{total_frames} ({frame_progress:.1f}%): samples {frame_start}-{frame_end}\")\n",
    "                \n",
    "                # Load frame\n",
    "                audio_frame, _ = raw[:, frame_start:frame_end]\n",
    "                audio_frame = audio_frame.flatten()\n",
    "                \n",
    "                # Calculate timestamp\n",
    "                timestamp = frame_start / fs\n",
    "                \n",
    "                print(f\"         ⏰ Time: {timestamp:.1f}s - {timestamp + FRAME_DURATION_SEC:.1f}s\")\n",
    "                \n",
    "                # Calculate apnea label using proportion-based approach\n",
    "                apnea_label, apnea_proportion = label_temporal_frame(\n",
    "                    timestamp, FRAME_DURATION_SEC, apnea_events, APNEA_THRESHOLD\n",
    "                )\n",
    "                \n",
    "                print(f\"         🏷️  Apnea proportion: {apnea_proportion:.3f}, Label: {apnea_label}\")\n",
    "                \n",
    "                # Extract comprehensive features\n",
    "                print(f\"         🎯 Extracting features...\")\n",
    "                features = extract_comprehensive_features(audio_frame, fs)\n",
    "                \n",
    "                # Create feature record\n",
    "                feature_record = {\n",
    "                    'patient_id': patient_folder_name,\n",
    "                    'timestamp': timestamp,\n",
    "                    'frame_duration': FRAME_DURATION_SEC,\n",
    "                    'apnea_label': apnea_label,\n",
    "                    'apnea_proportion': apnea_proportion,\n",
    "                    **{f'clean_{k}': v for k, v in features.items()}\n",
    "                }\n",
    "                \n",
    "                patient_features.append(feature_record)\n",
    "                frame_count += 1\n",
    "                \n",
    "                print(f\"         ✅ Frame {frame_count} processed successfully\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error processing {edf_file}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Final patient summary\n",
    "    elapsed_time = time.time() - start_time\n",
    "    apnea_count = sum(1 for f in patient_features if f['apnea_label'] == 1)\n",
    "    apnea_percentage = (apnea_count / len(patient_features) * 100) if patient_features else 0\n",
    "    \n",
    "    if patient_features:\n",
    "        avg_apnea_proportion = np.mean([f['apnea_proportion'] for f in patient_features])\n",
    "    else:\n",
    "        avg_apnea_proportion = 0\n",
    "    \n",
    "    print(f\"\\n🏁 PATIENT {patient_folder_name} COMPLETE:\")\n",
    "    print(f\"   📊 Total 30-second frames extracted: {len(patient_features)}\")\n",
    "    print(f\"   🚨 Apnea frames (>{APNEA_THRESHOLD*100}% threshold): {apnea_count} ({apnea_percentage:.1f}%)\")\n",
    "    print(f\"   😴 Normal frames: {len(patient_features) - apnea_count} ({100-apnea_percentage:.1f}%)\")\n",
    "    print(f\"   📈 Average apnea proportion: {avg_apnea_proportion:.3f}\")\n",
    "    print(f\"   ⏱️  Processing time: {elapsed_time:.1f} seconds\")\n",
    "    \n",
    "    if elapsed_time > 0:\n",
    "        print(f\"   📈 Frames per minute: {len(patient_features)/(elapsed_time/60):.1f}\")\n",
    "    \n",
    "    return patient_features\n",
    "\n",
    "# COMMENTED OUT - Noise injection and denoising functions for future use\n",
    "# def add_noise(clean_signal, noise_signal, sr, noise_level_rms_ratio):\n",
    "#     \"\"\"Mixes a clean signal with a noise signal using the provided RMS ratio logic.\"\"\"\n",
    "#     # Implementation preserved for future use\n",
    "#     pass\n",
    "# \n",
    "# def run_denoiser_script(script_name, input_wav_path, output_wav_path, denoiser_script_map, sr, current_temp_dir):\n",
    "#     \"\"\"Wrapper for calling external denoiser scripts\"\"\"\n",
    "#     # Implementation preserved for future use\n",
    "#     pass\n",
    "\n",
    "print(\"Enhanced helper functions and process_single_patient function defined for 30-second temporal feature extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up parallel processing capabilities... ---\n",
      "✅ Improved parallel processing functions ready! (4 cores max, better error handling)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Parallel Processing Setup (Before Main Execution)\n",
    "print(\"--- Setting up parallel processing capabilities... ---\")\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def setup_parallel_processing():\n",
    "    \"\"\"Setup directories and tracking for parallel processing\"\"\"\n",
    "    temp_dir = Path('./temp_features/')\n",
    "    temp_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    final_dataset_path = './clean_features_dataset_30sec_incremental.csv'\n",
    "    progress_file = temp_dir / 'progress.txt'\n",
    "    \n",
    "    return temp_dir, final_dataset_path, progress_file\n",
    "\n",
    "def get_completed_patients(progress_file):\n",
    "    \"\"\"Get list of already processed patients\"\"\"\n",
    "    if progress_file.exists():\n",
    "        with open(progress_file, 'r') as f:\n",
    "            return set(line.strip() for line in f)\n",
    "    return set()\n",
    "\n",
    "def append_to_final_dataset(patient_csv, final_dataset_path, patient_id, progress_file):\n",
    "    \"\"\"Thread-safe append to final dataset\"\"\"\n",
    "    patient_df = pd.read_csv(patient_csv)\n",
    "    \n",
    "    # Lock-free append (pandas handles this well)\n",
    "    if Path(final_dataset_path).exists():\n",
    "        # Read, append, write\n",
    "        existing_df = pd.read_csv(final_dataset_path)\n",
    "        combined_df = pd.concat([existing_df, patient_df], ignore_index=True)\n",
    "        combined_df.to_csv(final_dataset_path, index=False)\n",
    "    else:\n",
    "        # First patient - just copy\n",
    "        patient_df.to_csv(final_dataset_path, index=False)\n",
    "    \n",
    "    # Update progress tracking\n",
    "    with open(progress_file, 'a') as f:\n",
    "        f.write(f\"{patient_id}\\n\")\n",
    "    \n",
    "    current_size = len(pd.read_csv(final_dataset_path))\n",
    "    print(f\"📊 Dataset now has {current_size:,} total frames\")\n",
    "\n",
    "def process_patient_safe(patient_id, temp_dir, final_dataset_path, progress_file, patient_base_dir):\n",
    "    \"\"\"Safe wrapper for patient processing with proper resource management\"\"\"\n",
    "    lock_file = temp_dir / f\"{patient_id}.lock\"\n",
    "    patient_csv = temp_dir / f\"{patient_id}_features.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Check if already completed\n",
    "        completed_patients = get_completed_patients(progress_file)\n",
    "        if patient_id in completed_patients:\n",
    "            print(f\"✅ {patient_id} already in final dataset\")\n",
    "            return True\n",
    "        \n",
    "        # Check if CSV exists (completed but not merged)\n",
    "        if patient_csv.exists():\n",
    "            print(f\"📁 {patient_id} features found, merging to dataset...\")\n",
    "            append_to_final_dataset(patient_csv, final_dataset_path, patient_id, progress_file)\n",
    "            patient_csv.unlink()  # Remove temp file after merging\n",
    "            return True\n",
    "        \n",
    "        # Try to acquire processing lock\n",
    "        try:\n",
    "            lock_file.touch(exist_ok=False)\n",
    "            print(f\"🔄 Processing {patient_id}...\")\n",
    "            \n",
    "            # Process the patient with resource management\n",
    "            patient_features = process_single_patient_safe(patient_id, patient_base_dir)\n",
    "            \n",
    "            if patient_features:\n",
    "                # Save individual patient features\n",
    "                patient_df = pd.DataFrame(patient_features)\n",
    "                patient_df.to_csv(patient_csv, index=False)\n",
    "                \n",
    "                # Append to final dataset\n",
    "                append_to_final_dataset(patient_csv, final_dataset_path, patient_id, progress_file)\n",
    "                \n",
    "                # Cleanup\n",
    "                patient_csv.unlink()  # Remove temp file after merging\n",
    "            \n",
    "            lock_file.unlink()  # Remove lock\n",
    "            print(f\"✅ {patient_id} completed and merged\")\n",
    "            return True\n",
    "            \n",
    "        except FileExistsError:\n",
    "            print(f\"⏳ {patient_id} being processed by another core...\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {patient_id}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        if lock_file.exists():\n",
    "            lock_file.unlink()\n",
    "        return False\n",
    "\n",
    "def process_single_patient_safe(patient_folder_name, patient_base_dir):\n",
    "    \"\"\"Memory-efficient version of process_single_patient for multiprocessing\"\"\"\n",
    "    # Re-import everything needed in the subprocess\n",
    "    import os\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import librosa\n",
    "    import mne\n",
    "    import sys\n",
    "    sys.path.append('../src')\n",
    "    from working_with_xml import extract_apnea_events\n",
    "    \n",
    "    # Suppress warnings in subprocess\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Use configuration from global scope (these need to be defined)\n",
    "    AUDIO_CHANNEL_NAME = 'Mic'\n",
    "    FRAME_DURATION_SEC = 30.0\n",
    "    OVERLAP_RATIO = 0.5\n",
    "    APNEA_THRESHOLD = 0.1\n",
    "    \n",
    "    def parse_respironics_rml_local(rml_path):\n",
    "        apnea_event_data = extract_apnea_events(rml_path, output_csv=None)\n",
    "        return [(float(start), float(end)) for event_type, start, end in apnea_event_data]\n",
    "    \n",
    "    def calculate_apnea_proportion_local(frame_start_sec, frame_duration_sec, apnea_events):\n",
    "        frame_end_sec = frame_start_sec + frame_duration_sec\n",
    "        apnea_seconds = 0\n",
    "        for start, end in apnea_events:\n",
    "            overlap_start = max(frame_start_sec, start)\n",
    "            overlap_end = min(frame_end_sec, end)\n",
    "            if overlap_start < overlap_end:\n",
    "                apnea_seconds += (overlap_end - overlap_start)\n",
    "        return apnea_seconds / frame_duration_sec\n",
    "    \n",
    "    def label_temporal_frame_local(frame_start_sec, frame_duration_sec, apnea_events, threshold=0.1):\n",
    "        proportion = calculate_apnea_proportion_local(frame_start_sec, frame_duration_sec, apnea_events)\n",
    "        return 1 if proportion > threshold else 0, proportion\n",
    "    \n",
    "    def extract_features_local(frame, sr):\n",
    "        \"\"\"Simplified feature extraction for multiprocessing\"\"\"\n",
    "        if len(frame) == 0:\n",
    "            return {}\n",
    "        \n",
    "        try:\n",
    "            # Basic features\n",
    "            rms = librosa.feature.rms(y=frame).mean()\n",
    "            zcr = librosa.feature.zero_crossing_rate(y=frame).mean()\n",
    "            centroid = librosa.feature.spectral_centroid(y=frame, sr=sr).mean()\n",
    "            bandwidth = librosa.feature.spectral_bandwidth(y=frame, sr=sr).mean()\n",
    "            rolloff = librosa.feature.spectral_rolloff(y=frame, sr=sr).mean()\n",
    "            \n",
    "            # MFCCs\n",
    "            mfccs = librosa.feature.mfcc(y=frame, sr=sr, n_mfcc=13)\n",
    "            mfccs_mean = mfccs.mean(axis=1)\n",
    "            mfccs_std = mfccs.std(axis=1)\n",
    "            \n",
    "            features = {\n",
    "                'rms': rms, 'zcr': zcr, 'centroid': centroid,\n",
    "                'bandwidth': bandwidth, 'rolloff': rolloff\n",
    "            }\n",
    "            \n",
    "            # Add MFCCs\n",
    "            for i, (mean_val, std_val) in enumerate(zip(mfccs_mean, mfccs_std), 1):\n",
    "                features[f'mfcc_{i}_mean'] = mean_val\n",
    "                features[f'mfcc_{i}_std'] = std_val\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Feature extraction error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    # Main processing\n",
    "    start_time = time.time()\n",
    "    print(f\"🔄 Starting {patient_folder_name}...\")\n",
    "    \n",
    "    patient_local_dir = os.path.join(patient_base_dir, patient_folder_name)\n",
    "    patient_features = []\n",
    "    \n",
    "    try:\n",
    "        # Find files\n",
    "        edf_files = [f for f in os.listdir(patient_local_dir) if f.endswith('.edf')]\n",
    "        rml_files = [f for f in os.listdir(patient_local_dir) if f.endswith('.rml')]\n",
    "        \n",
    "        if not edf_files or not rml_files:\n",
    "            print(f\"❌ Missing files for {patient_folder_name}\")\n",
    "            return []\n",
    "        \n",
    "        # Load apnea events\n",
    "        rml_path = os.path.join(patient_local_dir, rml_files[0])\n",
    "        apnea_events = parse_respironics_rml_local(rml_path)\n",
    "        \n",
    "        # Process EDF file\n",
    "        edf_path = os.path.join(patient_local_dir, edf_files[0])\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "        \n",
    "        if AUDIO_CHANNEL_NAME not in raw.ch_names:\n",
    "            print(f\"❌ No {AUDIO_CHANNEL_NAME} channel in {patient_folder_name}\")\n",
    "            return []\n",
    "        \n",
    "        raw.pick_channels([AUDIO_CHANNEL_NAME])\n",
    "        fs = int(raw.info['sfreq'])\n",
    "        \n",
    "        # Frame parameters\n",
    "        frame_size_samples = int(FRAME_DURATION_SEC * fs)\n",
    "        step_samples = int(frame_size_samples * (1 - OVERLAP_RATIO))\n",
    "        \n",
    "        frame_count = 0\n",
    "        max_frames = 200  # Limit frames per patient to prevent memory issues\n",
    "        \n",
    "        # Process frames\n",
    "        for frame_start in range(0, raw.n_times - frame_size_samples + 1, step_samples):\n",
    "            if frame_count >= max_frames:\n",
    "                break\n",
    "                \n",
    "            frame_end = frame_start + frame_size_samples\n",
    "            \n",
    "            # Load frame data\n",
    "            audio_frame, _ = raw[:, frame_start:frame_end]\n",
    "            audio_frame = audio_frame.flatten()\n",
    "            \n",
    "            timestamp = frame_start / fs\n",
    "            \n",
    "            # Get labels\n",
    "            apnea_label, apnea_proportion = label_temporal_frame_local(\n",
    "                timestamp, FRAME_DURATION_SEC, apnea_events, APNEA_THRESHOLD\n",
    "            )\n",
    "            \n",
    "            # Extract features\n",
    "            features = extract_features_local(audio_frame, fs)\n",
    "            \n",
    "            if features:  # Only add if feature extraction succeeded\n",
    "                feature_record = {\n",
    "                    'patient_id': patient_folder_name,\n",
    "                    'timestamp': timestamp,\n",
    "                    'frame_duration': FRAME_DURATION_SEC,\n",
    "                    'apnea_label': apnea_label,\n",
    "                    'apnea_proportion': apnea_proportion,\n",
    "                    **{f'clean_{k}': v for k, v in features.items()}\n",
    "                }\n",
    "                patient_features.append(feature_record)\n",
    "                frame_count += 1\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"✅ {patient_folder_name}: {len(patient_features)} frames in {elapsed:.1f}s\")\n",
    "        return patient_features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {patient_folder_name} failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Global variables for multiprocessing (required to avoid pickle errors)\n",
    "_global_temp_dir = None\n",
    "_global_final_dataset_path = None\n",
    "_global_progress_file = None\n",
    "_global_patient_base_dir = None\n",
    "\n",
    "def _process_wrapper_global(patient_id):\n",
    "    \"\"\"Global wrapper function that can be pickled by multiprocessing\"\"\"\n",
    "    return process_patient_safe(\n",
    "        patient_id, \n",
    "        _global_temp_dir, \n",
    "        _global_final_dataset_path, \n",
    "        _global_progress_file, \n",
    "        _global_patient_base_dir\n",
    "    )\n",
    "\n",
    "def run_parallel_extraction(patient_list, patient_base_dir, max_workers=4):\n",
    "    \"\"\"Run parallel feature extraction with better resource management\"\"\"\n",
    "    global _global_temp_dir, _global_final_dataset_path, _global_progress_file, _global_patient_base_dir\n",
    "    \n",
    "    # Reduce workers to prevent memory issues\n",
    "    max_workers = min(max_workers, 4)  # Limit to 4 cores max\n",
    "    \n",
    "    # Setup\n",
    "    temp_dir, final_dataset_path, progress_file = setup_parallel_processing()\n",
    "    \n",
    "    # Set globals for multiprocessing\n",
    "    _global_temp_dir = temp_dir\n",
    "    _global_final_dataset_path = final_dataset_path  \n",
    "    _global_progress_file = progress_file\n",
    "    _global_patient_base_dir = patient_base_dir\n",
    "    \n",
    "    print(f\"🚀 Starting parallel processing with {max_workers} workers...\")\n",
    "    print(f\"📁 Temp dir: {temp_dir}\")\n",
    "    print(f\"📊 Final dataset: {final_dataset_path}\")\n",
    "    print(f\"👥 Processing patients: {patient_list}\")\n",
    "    \n",
    "    completed = 0\n",
    "    failed = 0\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all jobs using the global wrapper\n",
    "        futures = {executor.submit(_process_wrapper_global, pid): pid for pid in patient_list}\n",
    "        \n",
    "        for future in futures:\n",
    "            try:\n",
    "                result = future.result(timeout=600)  # 10 minute timeout per patient\n",
    "                if result:\n",
    "                    completed += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "                patient_id = futures[future]\n",
    "                print(f\"🎯 Progress: {completed}/{len(patient_list)} completed, {failed} failed ({patient_id})\")\n",
    "            except Exception as e:\n",
    "                patient_id = futures[future]\n",
    "                print(f\"❌ Error with {patient_id}: {e}\")\n",
    "                failed += 1\n",
    "    \n",
    "    # Final summary\n",
    "    if Path(final_dataset_path).exists():\n",
    "        final_df = pd.read_csv(final_dataset_path)\n",
    "        print(f\"\\n🎉 PARALLEL PROCESSING COMPLETE!\")\n",
    "        print(f\"📊 Final dataset: {final_df.shape}\")\n",
    "        print(f\"👥 Patients: {final_df['patient_id'].nunique()}\")\n",
    "        print(f\"⏱️  Total frames: {len(final_df):,}\")\n",
    "        print(f\"✅ Completed: {completed}, ❌ Failed: {failed}\")\n",
    "        if len(final_df) > 0:\n",
    "            print(f\"🚨 Apnea frames: {final_df['apnea_label'].sum():,} ({final_df['apnea_label'].mean()*100:.1f}%)\")\n",
    "        return final_dataset_path\n",
    "    else:\n",
    "        print(\"❌ No final dataset created\")\n",
    "        return None\n",
    "\n",
    "# Set the flag for parallel processing\n",
    "USE_PARALLEL_PROCESSING = True  # Set to True to enable parallel processing\n",
    "\n",
    "print(\"✅ Improved parallel processing functions ready! (4 cores max, better error handling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Executing clean feature extraction with progress tracking... ---\n",
      "🔍 Auto-detecting patient folders...\n",
      "📁 Found 24 patient folders: ['patient_01', 'patient_02', 'patient_03', 'patient_04', 'patient_05', 'patient_06', 'patient_07', 'patient_08', 'patient_09', 'patient_10', 'patient_11', 'patient_12', 'patient_13', 'patient_14', 'patient_15', 'patient_16', 'patient_17', 'patient_18', 'patient_19', 'patient_20', 'patient_21', 'patient_22', 'patient_23', 'patient_24']\n",
      "🐛 DEBUG MODE: Processing only 6 patients\n",
      "\n",
      "🚀 PARALLEL PROCESSING MODE ENABLED\n",
      "👥 Processing 6 patients with 6 cores\n",
      "⚡ Expected to complete in one cycle!\n",
      "🚀 Starting parallel processing with 4 workers...\n",
      "📁 Temp dir: temp_features\n",
      "📊 Final dataset: ./clean_features_dataset_30sec_incremental.csv\n",
      "👥 Processing patients: ['patient_01', 'patient_02', 'patient_03', 'patient_04', 'patient_05', 'patient_06']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error with patient_01: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "❌ Error with patient_02: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "❌ Error with patient_03: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "❌ Error with patient_04: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "❌ Error with patient_05: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "❌ Error with patient_06: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "❌ No final dataset created\n",
      "\n",
      "================================================================================\n",
      "🏁 FEATURE EXTRACTION COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Execute Processing - Choose Sequential or Parallel Mode\n",
    "print(\"--- Executing clean feature extraction with progress tracking... ---\")\n",
    "\n",
    "# Find patient folders\n",
    "if not PATIENT_FOLDERS_TO_PROCESS:\n",
    "    # Auto-detect patient folders\n",
    "    print(\"🔍 Auto-detecting patient folders...\")\n",
    "    all_folders = [f for f in os.listdir(RAW_PATIENT_DATA_BASE_DIR) if os.path.isdir(os.path.join(RAW_PATIENT_DATA_BASE_DIR, f))]\n",
    "    patient_folders = [f for f in all_folders if 'patient' in f.lower()]\n",
    "    PATIENT_FOLDERS_TO_PROCESS = sorted(patient_folders)\n",
    "\n",
    "print(f\"📁 Found {len(PATIENT_FOLDERS_TO_PROCESS)} patient folders: {PATIENT_FOLDERS_TO_PROCESS}\")\n",
    "\n",
    "if DEBUG_MODE:\n",
    "    PATIENT_FOLDERS_TO_PROCESS = PATIENT_FOLDERS_TO_PROCESS[:DEBUG_PATIENT_COUNT]\n",
    "    print(f\"🐛 DEBUG MODE: Processing only {len(PATIENT_FOLDERS_TO_PROCESS)} patients\")\n",
    "\n",
    "# Check processing mode\n",
    "if USE_PARALLEL_PROCESSING and len(PATIENT_FOLDERS_TO_PROCESS) > 1:\n",
    "    print(f\"\\n🚀 PARALLEL PROCESSING MODE ENABLED\")\n",
    "    print(f\"👥 Processing {len(PATIENT_FOLDERS_TO_PROCESS)} patients with 6 cores\")\n",
    "    print(f\"⚡ Expected to complete in one cycle!\")\n",
    "    \n",
    "    # Run parallel processing\n",
    "    final_dataset_path = run_parallel_extraction(\n",
    "        PATIENT_FOLDERS_TO_PROCESS, \n",
    "        RAW_PATIENT_DATA_BASE_DIR, \n",
    "        max_workers=6\n",
    "    )\n",
    "    \n",
    "    if final_dataset_path:\n",
    "        # Load and display results\n",
    "        df = pd.read_csv(final_dataset_path)\n",
    "        print(f\"\\n📊 FINAL RESULTS:\")\n",
    "        print(f\"✅ Dataset saved to: {final_dataset_path}\")\n",
    "        print(f\"📋 Dataset shape: {df.shape}\")\n",
    "        print(f\"👥 Unique patients: {df['patient_id'].nunique()}\")\n",
    "        display(df.head())\n",
    "        \n",
    "else:\n",
    "    print(f\"\\n🔄 SEQUENTIAL PROCESSING MODE\")\n",
    "    print(f\"👥 Processing {len(PATIENT_FOLDERS_TO_PROCESS)} patients one by one\")\n",
    "    \n",
    "    # Sequential processing (original code)\n",
    "    total_patients = len(PATIENT_FOLDERS_TO_PROCESS)\n",
    "    all_features = []\n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    print(f\"\\n🚀 STARTING PROCESSING OF {total_patients} PATIENTS\")\n",
    "    print(f\"📊 Estimated time: {total_patients * 2:.0f}-{total_patients * 5:.0f} minutes\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Process all patients with enhanced progress tracking\n",
    "    for patient_idx, patient_folder in enumerate(PATIENT_FOLDERS_TO_PROCESS):\n",
    "        overall_progress = (patient_idx + 1) / total_patients * 100\n",
    "        elapsed_overall = time.time() - overall_start_time\n",
    "        \n",
    "        print(f\"\\n🔄 OVERALL PROGRESS: {patient_idx+1}/{total_patients} ({overall_progress:.1f}%)\")\n",
    "        print(f\"⏱️  Overall elapsed time: {elapsed_overall/60:.1f} minutes\")\n",
    "        \n",
    "        if patient_idx > 0:\n",
    "            avg_time_per_patient = elapsed_overall / patient_idx\n",
    "            estimated_remaining = avg_time_per_patient * (total_patients - patient_idx)\n",
    "            print(f\"⏳ Estimated remaining time: {estimated_remaining/60:.1f} minutes\")\n",
    "        \n",
    "        # Process single patient with detailed tracking\n",
    "        patient_features = process_single_patient(patient_folder, RAW_PATIENT_DATA_BASE_DIR, patient_idx, total_patients)\n",
    "        all_features.extend(patient_features)\n",
    "        \n",
    "        # Running totals\n",
    "        running_total_features = len(all_features)\n",
    "        running_apnea_count = sum(1 for f in all_features if f['apnea_label'] == 1)\n",
    "        running_apnea_percentage = (running_apnea_count / running_total_features * 100) if running_total_features else 0\n",
    "        \n",
    "        print(f\"\\n📈 RUNNING TOTALS AFTER {patient_idx+1} PATIENTS:\")\n",
    "        print(f\"   📊 Total features so far: {running_total_features:,}\")\n",
    "        print(f\"   🚨 Total apnea frames: {running_apnea_count:,} ({running_apnea_percentage:.1f}%)\")\n",
    "        print(f\"   😴 Total normal frames: {running_total_features - running_apnea_count:,} ({100-running_apnea_percentage:.1f}%)\")\n",
    "\n",
    "    # Final processing summary\n",
    "    total_elapsed = time.time() - overall_start_time\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🎉 ALL PROCESSING COMPLETE!\")\n",
    "    print(f\"⏱️  Total processing time: {total_elapsed/60:.1f} minutes ({total_elapsed:.1f} seconds)\")\n",
    "    print(f\"📊 Total features extracted: {len(all_features):,}\")\n",
    "    print(f\"👥 Patients processed: {total_patients}\")\n",
    "    print(f\"📈 Average features per patient: {len(all_features)/total_patients:.0f}\")\n",
    "    print(f\"⚡ Processing rate: {len(all_features)/total_elapsed:.1f} features/second\")\n",
    "\n",
    "    # Convert to DataFrame and save with enhanced reporting\n",
    "    if all_features:\n",
    "        print(f\"\\n💾 Converting to DataFrame and saving...\")\n",
    "        df = pd.DataFrame(all_features)\n",
    "        \n",
    "        # Enhanced dataset statistics\n",
    "        print(f\"\\n📊 FINAL DATASET STATISTICS:\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Total frames: {len(df):,}\")\n",
    "        print(f\"Unique patients: {df['patient_id'].nunique()}\")\n",
    "        print(f\"Average frames per patient: {len(df)/df['patient_id'].nunique():.0f}\")\n",
    "        print(f\"Total duration: {df['timestamp'].max()/3600:.1f} hours\")\n",
    "        print(f\"Apnea frames: {df['apnea_label'].sum():,} ({df['apnea_label'].mean()*100:.2f}%)\")\n",
    "        print(f\"Non-apnea frames: {(df['apnea_label'] == 0).sum():,} ({(1-df['apnea_label'].mean())*100:.2f}%)\")\n",
    "        \n",
    "        # Per-patient breakdown\n",
    "        print(f\"\\n👥 PER-PATIENT BREAKDOWN:\")\n",
    "        print(f\"{'='*50}\")\n",
    "        patient_stats = df.groupby('patient_id').agg({\n",
    "            'apnea_label': ['count', 'sum', 'mean'],\n",
    "            'timestamp': ['min', 'max']\n",
    "        }).round(3)\n",
    "        \n",
    "        for patient in patient_stats.index:\n",
    "            frame_count = patient_stats.loc[patient, ('apnea_label', 'count')]\n",
    "            apnea_count = patient_stats.loc[patient, ('apnea_label', 'sum')]\n",
    "            apnea_rate = patient_stats.loc[patient, ('apnea_label', 'mean')] * 100\n",
    "            duration_hours = (patient_stats.loc[patient, ('timestamp', 'max')] - \n",
    "                             patient_stats.loc[patient, ('timestamp', 'min')]) / 3600\n",
    "            print(f\"{patient}: {frame_count:,} frames, {apnea_count:,} apnea ({apnea_rate:.1f}%), {duration_hours:.1f}h\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_file = os.path.join(CSV_OUTPUT_PATH, 'clean_features_dataset_30sec.csv')\n",
    "        print(f\"\\n💾 Saving dataset to CSV...\")\n",
    "        df.to_csv(output_file, index=False)\n",
    "        file_size_mb = os.path.getsize(output_file) / (1024*1024)\n",
    "        \n",
    "        print(f\"✅ Dataset saved successfully!\")\n",
    "        print(f\"📁 File path: {output_file}\")\n",
    "        print(f\"📏 File size: {file_size_mb:.1f} MB\")\n",
    "        print(f\"🔢 Columns: {len(df.columns)}\")\n",
    "        \n",
    "        # Display sample data\n",
    "        print(f\"\\n📋 SAMPLE DATA (First 5 rows):\")\n",
    "        display(df.head())\n",
    "        \n",
    "        print(f\"\\n🎯 Dataset is ready for model training!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No features extracted. Check your patient data and configuration.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"🏁 FEATURE EXTRACTION COMPLETE!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Executing clean feature extraction with detailed progress... ---\n",
      "📁 Found 6 patient folders: ['patient_01', 'patient_02', 'patient_03', 'patient_04', 'patient_05', 'patient_06']\n",
      "🐛 DEBUG MODE: Processing only 6 patients\n",
      "\n",
      "🚀 STARTING PROCESSING OF 6 PATIENTS\n",
      "📊 Estimated time: 12-30 minutes\n",
      "================================================================================\n",
      "\n",
      "🔄 OVERALL PROGRESS: 1/6 (16.7%)\n",
      "⏱️  Overall elapsed time: 0.0 minutes\n",
      "\n",
      "============================================================\n",
      "PATIENT 1/6: patient_01\n",
      "============================================================\n",
      "🔍 Scanning files in F:\\Solo All In One Docs\\Evaluating-Noise-Reduction-Techniques\\data\\sleep_data\\patient_01...\n",
      "   Found 5 EDF files: ['00001000-100507[001].edf', '00001000-100507[002].edf', '00001000-100507[003].edf', '00001000-100507[004].edf', '00001000-100507[005].edf']\n",
      "   Found 1 RML files: ['00001000-100507.rml']\n",
      "\n",
      "📁 Processing EDF 1/5: 00001000-100507[001].edf\n",
      "   📋 Loading apnea events from 00001000-100507.rml...\n",
      "ObstructiveApnea: 41.0s to 54.5s (duration: 13.5s)\n",
      "ObstructiveApnea: 91.5s to 110.5s (duration: 19.0s)\n",
      "ObstructiveApnea: 436.0s to 448.0s (duration: 12.0s)\n",
      "ObstructiveApnea: 472.0s to 482.5s (duration: 10.5s)\n",
      "ObstructiveApnea: 494.0s to 505.0s (duration: 11.0s)\n",
      "ObstructiveApnea: 638.0s to 653.5s (duration: 15.5s)\n",
      "ObstructiveApnea: 668.0s to 680.5s (duration: 12.5s)\n",
      "ObstructiveApnea: 744.0s to 754.5s (duration: 10.5s)\n",
      "ObstructiveApnea: 769.0s to 781.5s (duration: 12.5s)\n",
      "ObstructiveApnea: 798.0s to 809.5s (duration: 11.5s)\n",
      "ObstructiveApnea: 840.5s to 851.0s (duration: 10.5s)\n",
      "Hypopnea: 864.0s to 877.5s (duration: 13.5s)\n",
      "ObstructiveApnea: 950.5s to 965.0s (duration: 14.5s)\n",
      "ObstructiveApnea: 1002.0s to 1013.0s (duration: 11.0s)\n",
      "ObstructiveApnea: 1042.5s to 1056.0s (duration: 13.5s)\n",
      "Hypopnea: 1083.0s to 1102.5s (duration: 19.5s)\n",
      "Hypopnea: 1160.0s to 1185.0s (duration: 25.0s)\n",
      "ObstructiveApnea: 1203.0s to 1215.5s (duration: 12.5s)\n",
      "ObstructiveApnea: 1323.5s to 1335.0s (duration: 11.5s)\n",
      "ObstructiveApnea: 1348.5s to 1360.5s (duration: 12.0s)\n",
      "ObstructiveApnea: 1395.0s to 1406.5s (duration: 11.5s)\n",
      "ObstructiveApnea: 1451.0s to 1462.0s (duration: 11.0s)\n",
      "ObstructiveApnea: 1482.5s to 1494.0s (duration: 11.5s)\n",
      "ObstructiveApnea: 1519.0s to 1533.5s (duration: 14.5s)\n",
      "MixedApnea: 1552.5s to 1568.0s (duration: 15.5s)\n",
      "ObstructiveApnea: 1593.0s to 1608.0s (duration: 15.0s)\n",
      "ObstructiveApnea: 3613.5s to 3626.0s (duration: 12.5s)\n",
      "Hypopnea: 3675.5s to 3692.5s (duration: 17.0s)\n",
      "Hypopnea: 3786.5s to 3797.5s (duration: 11.0s)\n",
      "Hypopnea: 3868.0s to 3883.5s (duration: 15.5s)\n",
      "Hypopnea: 3912.5s to 3927.5s (duration: 15.0s)\n",
      "Hypopnea: 3959.5s to 3976.5s (duration: 17.0s)\n",
      "Hypopnea: 4048.0s to 4063.0s (duration: 15.0s)\n",
      "Hypopnea: 4189.0s to 4205.0s (duration: 16.0s)\n",
      "ObstructiveApnea: 4228.5s to 4241.5s (duration: 13.0s)\n",
      "ObstructiveApnea: 4267.5s to 4282.0s (duration: 14.5s)\n",
      "Hypopnea: 4304.5s to 4321.5s (duration: 17.0s)\n",
      "Hypopnea: 4356.5s to 4370.5s (duration: 14.0s)\n",
      "ObstructiveApnea: 4401.5s to 4412.5s (duration: 11.0s)\n",
      "ObstructiveApnea: 4436.0s to 4447.0s (duration: 11.0s)\n",
      "ObstructiveApnea: 4468.0s to 4482.5s (duration: 14.5s)\n",
      "ObstructiveApnea: 4531.0s to 4545.0s (duration: 14.0s)\n",
      "Hypopnea: 4572.0s to 4587.5s (duration: 15.5s)\n",
      "Hypopnea: 4616.0s to 4629.0s (duration: 13.0s)\n",
      "ObstructiveApnea: 4765.0s to 4777.5s (duration: 12.5s)\n",
      "Hypopnea: 4792.0s to 4806.5s (duration: 14.5s)\n",
      "ObstructiveApnea: 4827.0s to 4840.5s (duration: 13.5s)\n",
      "ObstructiveApnea: 4876.5s to 4891.0s (duration: 14.5s)\n",
      "ObstructiveApnea: 4953.0s to 4968.5s (duration: 15.5s)\n",
      "ObstructiveApnea: 4987.5s to 4999.0s (duration: 11.5s)\n",
      "Hypopnea: 5018.0s to 5030.5s (duration: 12.5s)\n",
      "ObstructiveApnea: 5061.5s to 5074.0s (duration: 12.5s)\n",
      "ObstructiveApnea: 5101.5s to 5121.0s (duration: 19.5s)\n",
      "ObstructiveApnea: 5152.0s to 5165.0s (duration: 13.0s)\n",
      "ObstructiveApnea: 5171.0s to 5181.0s (duration: 10.0s)\n",
      "ObstructiveApnea: 5195.5s to 5207.5s (duration: 12.0s)\n",
      "ObstructiveApnea: 5232.5s to 5245.5s (duration: 13.0s)\n",
      "ObstructiveApnea: 5267.5s to 5283.0s (duration: 15.5s)\n",
      "ObstructiveApnea: 5304.0s to 5327.5s (duration: 23.5s)\n",
      "ObstructiveApnea: 5350.5s to 5365.0s (duration: 14.5s)\n",
      "ObstructiveApnea: 5380.5s to 5394.0s (duration: 13.5s)\n",
      "ObstructiveApnea: 5429.0s to 5453.5s (duration: 24.5s)\n",
      "ObstructiveApnea: 5477.0s to 5501.0s (duration: 24.0s)\n",
      "ObstructiveApnea: 5518.0s to 5535.0s (duration: 17.0s)\n",
      "ObstructiveApnea: 5554.5s to 5566.0s (duration: 11.5s)\n",
      "ObstructiveApnea: 5599.5s to 5620.5s (duration: 21.0s)\n",
      "ObstructiveApnea: 5639.5s to 5672.0s (duration: 32.5s)\n",
      "ObstructiveApnea: 5697.5s to 5712.5s (duration: 15.0s)\n",
      "ObstructiveApnea: 5729.5s to 5742.0s (duration: 12.5s)\n",
      "ObstructiveApnea: 5751.5s to 5777.0s (duration: 25.5s)\n",
      "ObstructiveApnea: 5803.5s to 5815.0s (duration: 11.5s)\n",
      "ObstructiveApnea: 5828.0s to 5841.5s (duration: 13.5s)\n",
      "ObstructiveApnea: 5865.0s to 5888.0s (duration: 23.0s)\n",
      "ObstructiveApnea: 5911.5s to 5935.0s (duration: 23.5s)\n",
      "ObstructiveApnea: 5951.5s to 5963.5s (duration: 12.0s)\n",
      "ObstructiveApnea: 5984.5s to 5995.5s (duration: 11.0s)\n",
      "ObstructiveApnea: 6006.0s to 6018.0s (duration: 12.0s)\n",
      "ObstructiveApnea: 6035.0s to 6059.0s (duration: 24.0s)\n",
      "ObstructiveApnea: 6076.0s to 6086.0s (duration: 10.0s)\n",
      "ObstructiveApnea: 6161.0s to 6172.5s (duration: 11.5s)\n",
      "ObstructiveApnea: 6184.0s to 6194.5s (duration: 10.5s)\n",
      "ObstructiveApnea: 6211.0s to 6222.5s (duration: 11.5s)\n",
      "ObstructiveApnea: 6233.0s to 6243.0s (duration: 10.0s)\n",
      "ObstructiveApnea: 6260.5s to 6275.5s (duration: 15.0s)\n",
      "ObstructiveApnea: 6292.5s to 6306.0s (duration: 13.5s)\n",
      "ObstructiveApnea: 6325.0s to 6338.0s (duration: 13.0s)\n",
      "ObstructiveApnea: 6350.5s to 6362.5s (duration: 12.0s)\n",
      "ObstructiveApnea: 6401.0s to 6411.5s (duration: 10.5s)\n",
      "ObstructiveApnea: 7063.0s to 7076.5s (duration: 13.5s)\n",
      "ObstructiveApnea: 7120.5s to 7136.5s (duration: 16.0s)\n",
      "ObstructiveApnea: 7678.5s to 7689.5s (duration: 11.0s)\n",
      "ObstructiveApnea: 7703.0s to 7722.0s (duration: 19.0s)\n",
      "ObstructiveApnea: 7742.0s to 7760.5s (duration: 18.5s)\n",
      "ObstructiveApnea: 7773.5s to 7792.0s (duration: 18.5s)\n",
      "ObstructiveApnea: 7815.5s to 7839.0s (duration: 23.5s)\n",
      "ObstructiveApnea: 7860.0s to 7882.0s (duration: 22.0s)\n",
      "ObstructiveApnea: 7904.5s to 7918.0s (duration: 13.5s)\n",
      "ObstructiveApnea: 7940.0s to 7954.0s (duration: 14.0s)\n",
      "ObstructiveApnea: 7978.5s to 7998.0s (duration: 19.5s)\n",
      "ObstructiveApnea: 9085.0s to 9096.5s (duration: 11.5s)\n",
      "ObstructiveApnea: 9126.0s to 9137.5s (duration: 11.5s)\n",
      "ObstructiveApnea: 9361.5s to 9374.0s (duration: 12.5s)\n",
      "ObstructiveApnea: 9398.0s to 9412.5s (duration: 14.5s)\n",
      "Hypopnea: 9443.5s to 9464.0s (duration: 20.5s)\n",
      "ObstructiveApnea: 9501.5s to 9515.0s (duration: 13.5s)\n",
      "ObstructiveApnea: 9551.5s to 9563.0s (duration: 11.5s)\n",
      "ObstructiveApnea: 9588.5s to 9602.0s (duration: 13.5s)\n",
      "ObstructiveApnea: 9625.0s to 9639.0s (duration: 14.0s)\n",
      "ObstructiveApnea: 9662.5s to 9678.5s (duration: 16.0s)\n",
      "ObstructiveApnea: 9705.5s to 9719.5s (duration: 14.0s)\n",
      "ObstructiveApnea: 9745.0s to 9759.5s (duration: 14.5s)\n",
      "ObstructiveApnea: 9786.5s to 9802.0s (duration: 15.5s)\n",
      "ObstructiveApnea: 9838.0s to 9854.0s (duration: 16.0s)\n",
      "ObstructiveApnea: 9883.0s to 9898.0s (duration: 15.0s)\n",
      "ObstructiveApnea: 9924.0s to 9939.5s (duration: 15.5s)\n",
      "ObstructiveApnea: 9967.5s to 9984.5s (duration: 17.0s)\n",
      "ObstructiveApnea: 10013.5s to 10033.5s (duration: 20.0s)\n",
      "ObstructiveApnea: 10095.5s to 10106.5s (duration: 11.0s)\n",
      "Hypopnea: 10129.5s to 10144.5s (duration: 15.0s)\n",
      "ObstructiveApnea: 10172.5s to 10183.0s (duration: 10.5s)\n",
      "Hypopnea: 10227.5s to 10243.5s (duration: 16.0s)\n",
      "ObstructiveApnea: 10268.5s to 10283.5s (duration: 15.0s)\n",
      "ObstructiveApnea: 10316.5s to 10332.0s (duration: 15.5s)\n",
      "ObstructiveApnea: 10361.0s to 10377.0s (duration: 16.0s)\n",
      "ObstructiveApnea: 10406.0s to 10423.5s (duration: 17.5s)\n",
      "ObstructiveApnea: 10447.0s to 10465.0s (duration: 18.0s)\n",
      "ObstructiveApnea: 10486.5s to 10506.0s (duration: 19.5s)\n",
      "ObstructiveApnea: 10537.0s to 10553.5s (duration: 16.5s)\n",
      "MixedApnea: 10584.0s to 10600.5s (duration: 16.5s)\n",
      "ObstructiveApnea: 10628.5s to 10645.0s (duration: 16.5s)\n",
      "Hypopnea: 10670.0s to 10695.0s (duration: 25.0s)\n",
      "ObstructiveApnea: 10727.0s to 10741.0s (duration: 14.0s)\n",
      "Hypopnea: 10774.0s to 10801.5s (duration: 27.5s)\n",
      "ObstructiveApnea: 10831.5s to 10846.5s (duration: 15.0s)\n",
      "Hypopnea: 10867.0s to 10887.0s (duration: 20.0s)\n",
      "Hypopnea: 10916.0s to 10928.5s (duration: 12.5s)\n",
      "Hypopnea: 11420.0s to 11440.0s (duration: 20.0s)\n",
      "Hypopnea: 11472.5s to 11505.5s (duration: 33.0s)\n",
      "Hypopnea: 11528.0s to 11548.5s (duration: 20.5s)\n",
      "MixedApnea: 11987.5s to 12002.5s (duration: 15.0s)\n",
      "Hypopnea: 12032.5s to 12048.5s (duration: 16.0s)\n",
      "Hypopnea: 12825.5s to 12838.5s (duration: 13.0s)\n",
      "ObstructiveApnea: 13018.5s to 13032.0s (duration: 13.5s)\n",
      "ObstructiveApnea: 13099.0s to 13120.0s (duration: 21.0s)\n",
      "ObstructiveApnea: 13155.0s to 13167.5s (duration: 12.5s)\n",
      "ObstructiveApnea: 13199.0s to 13218.0s (duration: 19.0s)\n",
      "ObstructiveApnea: 13260.5s to 13274.5s (duration: 14.0s)\n",
      "ObstructiveApnea: 13297.5s to 13317.0s (duration: 19.5s)\n",
      "ObstructiveApnea: 13374.0s to 13388.0s (duration: 14.0s)\n",
      "ObstructiveApnea: 13410.5s to 13426.0s (duration: 15.5s)\n",
      "ObstructiveApnea: 13482.0s to 13500.5s (duration: 18.5s)\n",
      "ObstructiveApnea: 13552.5s to 13567.5s (duration: 15.0s)\n",
      "ObstructiveApnea: 13594.0s to 13606.5s (duration: 12.5s)\n",
      "ObstructiveApnea: 13625.0s to 13640.5s (duration: 15.5s)\n",
      "Hypopnea: 13682.0s to 13700.5s (duration: 18.5s)\n",
      "Hypopnea: 13735.5s to 13751.0s (duration: 15.5s)\n",
      "Hypopnea: 13772.0s to 13790.5s (duration: 18.5s)\n",
      "Hypopnea: 13816.5s to 13830.0s (duration: 13.5s)\n",
      "Hypopnea: 13864.5s to 13880.5s (duration: 16.0s)\n",
      "ObstructiveApnea: 14077.5s to 14090.0s (duration: 12.5s)\n",
      "ObstructiveApnea: 14123.5s to 14136.5s (duration: 13.0s)\n",
      "Hypopnea: 14165.0s to 14179.0s (duration: 14.0s)\n",
      "Hypopnea: 14209.0s to 14228.5s (duration: 19.5s)\n",
      "Hypopnea: 14288.0s to 14302.5s (duration: 14.5s)\n",
      "ObstructiveApnea: 14442.0s to 14455.5s (duration: 13.5s)\n",
      "   ✅ Found 165 apnea events\n",
      "   🎵 Loading EDF file...\n",
      "   📊 Sample rate: 48000 Hz\n",
      "   ⏱️  Total duration: 60.0 minutes (3600 seconds)\n",
      "   🎤 Available channels: ['EEG A1-A2', 'EEG C3-A2', 'EEG C4-A1', 'EOG LOC-A2', 'EOG ROC-A2', 'EMG Chin', 'Leg 1', 'Leg 2', 'ECG I', 'RR', 'Snore', 'Flow Patient-0', 'Flow Patient-1', 'Effort THO', 'Effort ABD', 'SpO2', 'Body', 'PulseRate', 'Mic', 'Tracheal']\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "   ✅ Selected channel: Mic\n",
      "   📦 Processing in 30.0-second frames with 50.0% overlap\n",
      "   🎞️  Estimated frames: 239\n",
      "      🔄 Frame 1/239 (0.4%): samples 0-1440000\n",
      "         ⏰ Time: 0.0s - 30.0s\n",
      "         🏷️  Apnea proportion: 0.000, Label: 0\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 1 processed successfully\n",
      "      🔄 Frame 2/239 (0.8%): samples 720000-2160000\n",
      "         ⏰ Time: 15.0s - 45.0s\n",
      "         🏷️  Apnea proportion: 0.133, Label: 1\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 2 processed successfully\n",
      "      🔄 Frame 3/239 (1.3%): samples 1440000-2880000\n",
      "         ⏰ Time: 30.0s - 60.0s\n",
      "         🏷️  Apnea proportion: 0.450, Label: 1\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 3 processed successfully\n",
      "      🔄 Frame 4/239 (1.7%): samples 2160000-3600000\n",
      "         ⏰ Time: 45.0s - 75.0s\n",
      "         🏷️  Apnea proportion: 0.317, Label: 1\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 4 processed successfully\n",
      "      🔄 Frame 5/239 (2.1%): samples 2880000-4320000\n",
      "         ⏰ Time: 60.0s - 90.0s\n",
      "         🏷️  Apnea proportion: 0.000, Label: 0\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 5 processed successfully\n",
      "      🔄 Frame 6/239 (2.5%): samples 3600000-5040000\n",
      "         ⏰ Time: 75.0s - 105.0s\n",
      "         🏷️  Apnea proportion: 0.450, Label: 1\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 6 processed successfully\n",
      "      🔄 Frame 7/239 (2.9%): samples 4320000-5760000\n",
      "         ⏰ Time: 90.0s - 120.0s\n",
      "         🏷️  Apnea proportion: 0.633, Label: 1\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 7 processed successfully\n",
      "      🔄 Frame 8/239 (3.3%): samples 5040000-6480000\n",
      "         ⏰ Time: 105.0s - 135.0s\n",
      "         🏷️  Apnea proportion: 0.183, Label: 1\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 8 processed successfully\n",
      "      🔄 Frame 9/239 (3.8%): samples 5760000-7200000\n",
      "         ⏰ Time: 120.0s - 150.0s\n",
      "         🏷️  Apnea proportion: 0.000, Label: 0\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 9 processed successfully\n",
      "      🔄 Frame 10/239 (4.2%): samples 6480000-7920000\n",
      "         ⏰ Time: 135.0s - 165.0s\n",
      "         🏷️  Apnea proportion: 0.000, Label: 0\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 10 processed successfully\n",
      "      🔄 Frame 11/239 (4.6%): samples 7200000-8640000\n",
      "         ⏰ Time: 150.0s - 180.0s\n",
      "         🏷️  Apnea proportion: 0.000, Label: 0\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 11 processed successfully\n",
      "      🔄 Frame 12/239 (5.0%): samples 7920000-9360000\n",
      "         ⏰ Time: 165.0s - 195.0s\n",
      "         🏷️  Apnea proportion: 0.000, Label: 0\n",
      "         🎯 Extracting features...\n",
      "         ✅ Frame 12 processed successfully\n",
      "      🔄 Frame 13/239 (5.4%): samples 8640000-10080000\n",
      "         ⏰ Time: 180.0s - 210.0s\n",
      "         🏷️  Apnea proportion: 0.000, Label: 0\n",
      "         🎯 Extracting features...\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Execute Processing and Generate Dataset with Enhanced Progress Tracking\n",
    "print(\"--- Executing clean feature extraction with detailed progress... ---\")\n",
    "\n",
    "# Find patient folders\n",
    "if not PATIENT_FOLDERS_TO_PROCESS:\n",
    "    # Auto-detect patient folders\n",
    "    print(\"🔍 Auto-detecting patient folders...\")\n",
    "    all_folders = [f for f in os.listdir(RAW_PATIENT_DATA_BASE_DIR) if os.path.isdir(os.path.join(RAW_PATIENT_DATA_BASE_DIR, f))]\n",
    "    patient_folders = [f for f in all_folders if 'patient' in f.lower()]\n",
    "    PATIENT_FOLDERS_TO_PROCESS = sorted(patient_folders)\n",
    "\n",
    "print(f\"📁 Found {len(PATIENT_FOLDERS_TO_PROCESS)} patient folders: {PATIENT_FOLDERS_TO_PROCESS}\")\n",
    "\n",
    "if DEBUG_MODE:\n",
    "    PATIENT_FOLDERS_TO_PROCESS = PATIENT_FOLDERS_TO_PROCESS[:DEBUG_PATIENT_COUNT]\n",
    "    print(f\"🐛 DEBUG MODE: Processing only {len(PATIENT_FOLDERS_TO_PROCESS)} patients\")\n",
    "\n",
    "# Overall progress tracking\n",
    "total_patients = len(PATIENT_FOLDERS_TO_PROCESS)\n",
    "all_features = []\n",
    "overall_start_time = time.time()\n",
    "\n",
    "print(f\"\\n🚀 STARTING PROCESSING OF {total_patients} PATIENTS\")\n",
    "print(f\"📊 Estimated time: {total_patients * 2:.0f}-{total_patients * 5:.0f} minutes\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Process all patients with enhanced progress tracking\n",
    "for patient_idx, patient_folder in enumerate(PATIENT_FOLDERS_TO_PROCESS):\n",
    "    overall_progress = (patient_idx + 1) / total_patients * 100\n",
    "    elapsed_overall = time.time() - overall_start_time\n",
    "    \n",
    "    print(f\"\\n🔄 OVERALL PROGRESS: {patient_idx+1}/{total_patients} ({overall_progress:.1f}%)\")\n",
    "    print(f\"⏱️  Overall elapsed time: {elapsed_overall/60:.1f} minutes\")\n",
    "    \n",
    "    if patient_idx > 0:\n",
    "        avg_time_per_patient = elapsed_overall / patient_idx\n",
    "        estimated_remaining = avg_time_per_patient * (total_patients - patient_idx)\n",
    "        print(f\"⏳ Estimated remaining time: {estimated_remaining/60:.1f} minutes\")\n",
    "    \n",
    "    # Process single patient with detailed tracking\n",
    "    patient_features = process_single_patient(patient_folder, RAW_PATIENT_DATA_BASE_DIR, patient_idx, total_patients)\n",
    "    all_features.extend(patient_features)\n",
    "    \n",
    "    # Running totals\n",
    "    running_total_features = len(all_features)\n",
    "    running_apnea_count = sum(1 for f in all_features if f['apnea_label'] == 1)\n",
    "    running_apnea_percentage = (running_apnea_count / running_total_features * 100) if running_total_features else 0\n",
    "    \n",
    "    print(f\"\\n📈 RUNNING TOTALS AFTER {patient_idx+1} PATIENTS:\")\n",
    "    print(f\"   📊 Total features so far: {running_total_features:,}\")\n",
    "    print(f\"   🚨 Total apnea frames: {running_apnea_count:,} ({running_apnea_percentage:.1f}%)\")\n",
    "    print(f\"   😴 Total normal frames: {running_total_features - running_apnea_count:,} ({100-running_apnea_percentage:.1f}%)\")\n",
    "\n",
    "# Final processing summary\n",
    "total_elapsed = time.time() - overall_start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"🎉 ALL PROCESSING COMPLETE!\")\n",
    "print(f\"⏱️  Total processing time: {total_elapsed/60:.1f} minutes ({total_elapsed:.1f} seconds)\")\n",
    "print(f\"📊 Total features extracted: {len(all_features):,}\")\n",
    "print(f\"👥 Patients processed: {total_patients}\")\n",
    "print(f\"📈 Average features per patient: {len(all_features)/total_patients:.0f}\")\n",
    "print(f\"⚡ Processing rate: {len(all_features)/total_elapsed:.1f} features/second\")\n",
    "\n",
    "# Convert to DataFrame and save with enhanced reporting\n",
    "if all_features:\n",
    "    print(f\"\\n💾 Converting to DataFrame and saving...\")\n",
    "    df = pd.DataFrame(all_features)\n",
    "    \n",
    "    # Enhanced dataset statistics\n",
    "    print(f\"\\n📊 FINAL DATASET STATISTICS:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total frames: {len(df):,}\")\n",
    "    print(f\"Unique patients: {df['patient_id'].nunique()}\")\n",
    "    print(f\"Average frames per patient: {len(df)/df['patient_id'].nunique():.0f}\")\n",
    "    print(f\"Total duration: {df['timestamp'].max()/3600:.1f} hours\")\n",
    "    print(f\"Apnea frames: {df['apnea_label'].sum():,} ({df['apnea_label'].mean()*100:.2f}%)\")\n",
    "    print(f\"Non-apnea frames: {(df['apnea_label'] == 0).sum():,} ({(1-df['apnea_label'].mean())*100:.2f}%)\")\n",
    "    \n",
    "    # Per-patient breakdown\n",
    "    print(f\"\\n👥 PER-PATIENT BREAKDOWN:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    patient_stats = df.groupby('patient_id').agg({\n",
    "        'apnea_label': ['count', 'sum', 'mean'],\n",
    "        'timestamp': ['min', 'max']\n",
    "    }).round(3)\n",
    "    \n",
    "    for patient in patient_stats.index:\n",
    "        frame_count = patient_stats.loc[patient, ('apnea_label', 'count')]\n",
    "        apnea_count = patient_stats.loc[patient, ('apnea_label', 'sum')]\n",
    "        apnea_rate = patient_stats.loc[patient, ('apnea_label', 'mean')] * 100\n",
    "        duration_hours = (patient_stats.loc[patient, ('timestamp', 'max')] - \n",
    "                         patient_stats.loc[patient, ('timestamp', 'min')]) / 3600\n",
    "        print(f\"{patient}: {frame_count:,} frames, {apnea_count:,} apnea ({apnea_rate:.1f}%), {duration_hours:.1f}h\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    print(f\"\\n💾 Saving dataset to CSV...\")\n",
    "    df.to_csv(CSV_OUTPUT_PATH, index=False)\n",
    "    file_size_mb = os.path.getsize(CSV_OUTPUT_PATH) / (1024*1024)\n",
    "    \n",
    "    print(f\"✅ Dataset saved successfully!\")\n",
    "    print(f\"📁 File path: {CSV_OUTPUT_PATH}\")\n",
    "    print(f\"📏 File size: {file_size_mb:.1f} MB\")\n",
    "    print(f\"🔢 Columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(f\"\\n📋 SAMPLE DATA (First 5 rows):\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(f\"\\n🎯 Dataset is ready for model training!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No features extracted. Check your patient data and configuration.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"🏁 CLEAN FEATURE EXTRACTION COMPLETE!\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
