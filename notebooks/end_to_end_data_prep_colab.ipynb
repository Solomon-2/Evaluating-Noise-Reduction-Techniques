{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Sleep Apnea Data Preparation for Deep Learning (Colab)\n",
    "\n",
    "This notebook implements a storage-efficient pipeline to process a large number of patients for training an end-to-end sleep apnea detection model. The key goals are:\n",
    "\n",
    "1.  **Scalability:** Process up to 100 patients from a list of download links.\n",
    "2.  **Storage Efficiency:** Implement a **download-process-delete** workflow to avoid exceeding Google Colab's disk storage limits.\n",
    "3.  **Deep Learning Focus:** Convert raw audio into **mel-spectrograms**, which are ideal image-like inputs for Convolutional Neural Networks (CNNs).\n",
    "4.  **Standardization:** Downsample all audio to **16kHz**, the standard for most audio-based deep learning tasks.\n",
    "5.  **Final Output:** Save the entire processed dataset into two compressed NumPy (`.npz`) files (`spectrograms.npz` and `labels.npz`) in your Google Drive for easy loading in a separate model training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "# Install necessary libraries that are not pre-installed on Colab\n",
    "!pip install mne\n",
    "\n",
    "# --- Standard & Third-Party Libraries ---\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import mne\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Google Drive Integration ---\n",
    "from google.colab import drive\n",
    "\n",
    "print(\"✅ All libraries installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration - IMPORTANT: EDIT THIS CELL!\n",
    "print(\"--- Configuring the data preparation pipeline... ---\")\n",
    "\n",
    "# --- Google Drive Path ---\n",
    "# This is where your final .npz files will be saved. \n",
    "# The notebook will create this folder if it doesn't exist.\n",
    "DRIVE_OUTPUT_PATH = \"/content/drive/MyDrive/ApneaSpectrograms\" # <-- EDIT THIS!\n",
    "\n",
    "# --- Data Source ---\n",
    "# Path to the text file containing all download URLs.\n",
    "# You will need to upload this file to your Colab session.\n",
    "LINK_FILE = 'download_links.txt' # <-- UPLOAD THIS FILE TO COLAB\n",
    "\n",
    "# --- Processing Parameters ---\n",
    "NUM_PATIENTS_TO_PROCESS = 100 # Number of patients to download and process\n",
    "TARGET_SAMPLE_RATE = 16000  # 16kHz is the standard for audio deep learning\n",
    "CLIP_DURATION_SEC = 30.0    # Duration of each audio clip for spectrogram generation\n",
    "CLIP_OVERLAP_SEC = 15.0     # Create a new clip every 15 seconds (50% overlap)\n",
    "APNEA_THRESHOLD = 0.1       # Label clip as apnea if >10% of it contains an apnea event\n",
    "\n",
    "# --- Spectrogram Parameters ---\n",
    "N_MELS = 64              # Vertical resolution of the spectrogram (number of Mel bands)\n",
    "HOP_LENGTH = 512         # Controls the horizontal resolution (step size)\n",
    "\n",
    "# --- Setup ---\n",
    "# Mount Google Drive\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    print(f\"Google Drive mounted. Output will be saved to: {DRIVE_OUTPUT_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not mount Google Drive. {e}\")\n",
    "\n",
    "# Create the output directory on Google Drive\n",
    "os.makedirs(DRIVE_OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "print(\"✅ Configuration set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper Functions\n",
    "print(\"--- Defining helper functions for download, parsing, and processing... ---\")\n",
    "\n",
    "def group_links_by_patient(filepath):\n",
    "    \"\"\"Groups RML and EDF links from a text file by patient ID.\"\"\"\n",
    "    # ... (This function will be identical to the one in your download notebook) ...\n",
    "    pass\n",
    "\n",
    "def download_file_with_retry(url, local_path, max_retries=3):\n",
    "    \"\"\"Downloads a file with a simple retry mechanism.\"\"\"\n",
    "    # ... (This function will be identical to the one in your download notebook) ...\n",
    "    pass\n",
    "\n",
    "def extract_apnea_events(xml_file_path):\n",
    "    \"\"\"Parses an RML file to get a list of apnea event intervals.\"\"\"\n",
    "    # ... (This function will be identical to your existing one) ...\n",
    "    pass\n",
    "\n",
    "def audio_to_spectrogram(audio_clip, sr):\n",
    "    \"\"\"Converts a single audio clip to a mel-spectrogram.\"\"\"\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio_clip, sr=sr, n_mels=N_MELS, hop_length=HOP_LENGTH)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db.astype(np.float16) # Use float16 to save space\n",
    "\n",
    "def process_patient_to_spectrograms(patient_id, temp_dir):\n",
    "    \"\"\"Core function: loads patient audio, slices it, and converts to spectrograms.\"\"\"\n",
    "    # ... (This will be the main new function as described in our plan) ...\n",
    "    # 1. Find RML and EDF files in temp_dir\n",
    "    # 2. Parse RML for apnea events\n",
    "    # 3. Load and concatenate all EDF 'Mic' channels into a single audio array\n",
    "    # 4. Downsample the entire audio array to TARGET_SAMPLE_RATE\n",
    "    # 5. Slice the downsampled audio into 30-second clips with 15-second overlap\n",
    "    # 6. For each clip:\n",
    "    #    a. Calculate its apnea label (0 or 1)\n",
    "    #    b. Convert the audio clip to a mel-spectrogram\n",
    "    #    c. Append the spectrogram and label to lists\n",
    "    # 7. Return the lists of spectrograms and labels\n",
    "    pass\n",
    "\n",
    "print(\"✅ Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Main Processing Loop\n",
    "print(\"--- Starting main processing loop... ---\")\n",
    "\n",
    "all_spectrograms = []\n",
    "all_labels = []\n",
    "\n",
    "# 1. Group links from the uploaded file\n",
    "grouped_links = group_links_by_patient(LINK_FILE)\n",
    "valid_patients = [pid for pid, files in grouped_links.items() if files['rml'] and files['edf']]\n",
    "patients_to_process = valid_patients[:NUM_PATIENTS_TO_PROCESS]\n",
    "\n",
    "print(f\"Found {len(valid_patients)} valid patients. Processing the first {len(patients_to_process)}.\")\n",
    "\n",
    "# 2. Loop through each patient\n",
    "for patient_original_id in tqdm(patients_to_process, desc=\"Overall Patient Progress\"):\n",
    "    temp_patient_dir = os.path.join('/content/temp_data', patient_original_id)\n",
    "    os.makedirs(temp_patient_dir, exist_ok=True)\n",
    "    print(f\"\nProcessing {patient_original_id}...\")\n",
    "    \n",
    "    try:\n",
    "        # --- DOWNLOAD --- \n",
    "        # ... Download RML and all EDFs for this patient into temp_patient_dir ...\n",
    "        \n",
    "        # --- PROCESS --- \n",
    "        spectrograms, labels = process_patient_to_spectrograms(patient_original_id, temp_patient_dir)\n",
    "        if spectrograms:\n",
    "            all_spectrograms.extend(spectrograms)\n",
    "            all_labels.extend(labels)\n",
    "            print(f\"  -> Added {len(labels)} clips for {patient_original_id}. Total clips: {len(all_labels)}\")\n",
    "        else:\n",
    "            print(f\"  -> No clips processed for {patient_original_id}.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  -> ERROR processing {patient_original_id}: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        # --- DELETE --- \n",
    "        if os.path.exists(temp_patient_dir):\n",
    "            shutil.rmtree(temp_patient_dir)\n",
    "            print(f\"  -> Cleaned up temporary files for {patient_original_id}.\")\n",
    "\n",
    "print(\"\n✅ All patients processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Final Save to Google Drive\n",
    "print(\"--- Saving final dataset to Google Drive... ---\")\n",
    "\n",
    "if all_spectrograms:\n",
    "    # Convert lists to NumPy arrays\n",
    "    spectrogram_array = np.array(all_spectrograms)\n",
    "    label_array = np.array(all_labels, dtype=np.uint8)\n",
    "    \n",
    "    print(f\"Final spectrograms array shape: {spectrogram_array.shape}\")\n",
    "    print(f\"Final labels array shape: {label_array.shape}\")\n",
    "    \n",
    "    # Define output file paths\n",
    "    spectrogram_file = os.path.join(DRIVE_OUTPUT_PATH, 'spectrograms.npz')\n",
    "    label_file = os.path.join(DRIVE_OUTPUT_PATH, 'labels.npz')\n",
    "    \n",
    "    # Save using NumPy's compressed format\n",
    "    np.savez_compressed(spectrogram_file, spectrograms=spectrogram_array)\n",
    "    np.savez_compressed(label_file, labels=label_array)\n",
    "    \n",
    "    print(f\"\n✅ Successfully saved dataset!\")\n",
    "    print(f\"Spectrograms saved to: {spectrogram_file}\")\n",
    "    print(f\"Labels saved to: {label_file}\")\n",
    "    print(\"\nYou are now ready to use these files in your model training notebook.\")\n",
    "else:\n",
    "    print(\"❌ No data was processed, so no files were saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}